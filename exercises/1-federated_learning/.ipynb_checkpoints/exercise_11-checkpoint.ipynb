{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d20a0a-e183-43bc-8918-24d2f22ef634",
   "metadata": {},
   "source": [
    "## Part 2: Federated Learning\n",
    "\n",
    "You already have trained the model locally on your device with your (limited) data. We want now to extend this to FL.\n",
    "\n",
    "Some helper functions are already implemented in *clientlib.py*:\n",
    "- **wait_for_next_round**(server, last_trained_round=None, join_late_by_max=10):\n",
    "Wait until a new round has started. A round is considered new if it is younger than *join_late_by_max* seconds. The parameter *last_trained_round* may be used to indicate the last round that the client has last participated (i.e., wait for a round != last_trained_round).\n",
    "\n",
    "- **get_model_and_notify_client_started**(server, client_id):\n",
    "Registers the client at the server and downloads the current model and metadata. *metadata['round']* contains the current round number.\n",
    "\n",
    "- **upload_updated_model**(server, client_id, model, model_metadata):\n",
    "Upload an updated model from the server. *model_metadata* must be the same as returned by *get_model_and_notify_client_started*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31527d0-b1a5-4369-aea0-e092609f5a95",
   "metadata": {},
   "source": [
    "FL specifications:\n",
    "- train for **one epoch** with your local dataset in each round. Testing is not required (but may be interesting?)\n",
    "- use the same hyperparameters as in part 1\n",
    "- a round ends after 60s latest. If you upload your model too late, it is rejected by the server. **Do not cheat by changing model_metadata before uploading.**\n",
    "\n",
    "**Your Task:**\n",
    "- Implement the Federated Learning training on the client, for that in a loop do the following things\n",
    "- 1) Wait for the next round to start using the helper function `clientlib.wait_for_next_round()`.\n",
    "- 2) Download the newly averaged model from the server using the helper functions.\n",
    "- 3) Train your model with your data, similar to on-device training.\n",
    "- 4) Upload the model using the helper function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e98b6e3-c7bd-44bb-ad84-55f41f064c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_CLIENTS = 7  # number of participants in the lab\n",
    "CLIENT_ID = 2  # between 0 and TOTAL_CLIENTS-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d64fc72-8577-4c5f-996e-54f3c9ad9d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import device_data\n",
    "\n",
    "training_dataset = device_data.get_client_training_data(CLIENT_ID, TOTAL_CLIENTS)\n",
    "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=16)\n",
    "test_dataset = device_data.get_test_data()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35692a25-7929-4937-8469-11ab40fae52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting round\n",
      "downloaded model -> train (round 17)\n",
      "training took 12.9s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 18)\n",
      "training took 12.8s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 19)\n",
      "training took 12.9s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 20)\n",
      "training took 12.9s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 21)\n",
      "training took 12.8s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 22)\n",
      "training took 12.9s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 23)\n",
      "training took 12.8s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 24)\n",
      "training took 12.9s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 25)\n",
      "training took 13.1s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 26)\n",
      "training took 12.9s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 27)\n",
      "training took 12.9s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 28)\n",
      "training took 12.9s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 29)\n",
      "training took 12.8s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 30)\n",
      "training took 12.9s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 31)\n",
      "training took 12.8s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 32)\n",
      "training took 12.8s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 33)\n",
      "training took 12.8s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 34)\n",
      "training took 12.9s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 35)\n",
      "training took 13.0s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 36)\n",
      "training took 12.9s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 37)\n",
      "training took 12.5s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 38)\n",
      "training took 12.8s                                                             \n",
      "upload updated model\n",
      "Starting round\n",
      "downloaded model -> train (round 39)\n",
      "                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m#-to-be-done-by-student-----\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m#---------------------------\u001b[39;00m\n\u001b[1;32m     78\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, trainloader, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import clientlib\n",
    "SERVER = 'federated-learning.in8.itec.kit.edu:80'\n",
    "\n",
    "# this reaches 76% within 10 rounds with 4 clients\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "def train(model, optimizer, criterion, trainloader, device='cpu'):\n",
    "    #-to-be-done-by-student---------\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    #-------------------------------\n",
    "    for _, (inputs, targets) in enumerate(tqdm(trainloader, ncols=80,\n",
    "                                               file=sys.stdout, desc=\"Training\", leave=False)):\n",
    "        \n",
    "        #-to-be-done-by-student----\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #--------------------------\n",
    "    \n",
    "def test(model, testloader, device='cpu'):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    #-to-be-done-by-student---------\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    #-------------------------------\n",
    "    for _, (inputs, targets) in enumerate(tqdm(testloader, ncols=80,\n",
    "                                               file=sys.stdout, desc=\"Testing\", leave=False)):\n",
    "        #-to-be-done-by-student----\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        num_correct += sum(outputs.argmax(dim=1) == targets)\n",
    "        num_samples += len(targets)\n",
    "        #--------------------------\n",
    "        \n",
    "    return num_correct / num_samples\n",
    "\n",
    "last_trained_round = None\n",
    "#-to-be-done-by-student-----\n",
    "# model = CifarNet()\n",
    "#---------------------------\n",
    "\n",
    "while True:\n",
    "    print(\"Starting round\")\n",
    "    \n",
    "    #-to-be-done-by-student-----\n",
    "    clientlib.wait_for_next_round(SERVER, last_trained_round, join_late_by_max=10)\n",
    "    model, model_metadata = clientlib.get_model_and_notify_client_started(SERVER, CLIENT_ID)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    #---------------------------\n",
    "\n",
    "    print(f'downloaded model -> train (round {model_metadata[\"round\"]})')\n",
    "\n",
    "    start = time.time()\n",
    "    #-to-be-done-by-student-----\n",
    "    train(model, optimizer, criterion, train_loader, device=device)\n",
    "    #---------------------------\n",
    "    end = time.time()\n",
    "    print(f'training took {end-start:.1f}s')\n",
    "\n",
    "    print('upload updated model')\n",
    "    #-to-be-done-by-student-----\n",
    "    clientlib.upload_updated_model(SERVER, CLIENT_ID, model, model_metadata)\n",
    "    #---------------------------\n",
    "\n",
    "    last_trained_round = model_metadata['round']\n",
    "    \n",
    "    #we measure the accuracy after 10 rounds\n",
    "    if model_metadata['round'] == 10:\n",
    "        accuracy = test(model, test_loader, device=device)\n",
    "        print(f'Accuracy: ({accuracy:.2f})')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3abc7-a15d-44c3-983f-7b1076b122d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
