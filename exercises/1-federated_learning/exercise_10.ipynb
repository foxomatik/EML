{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fa2a19a-a0ec-46dc-aeef-efacd662be23",
   "metadata": {},
   "source": [
    "# Embedded ML Lab - Excercise 1- Federated Learning\n",
    "\n",
    "In this exercise, we will explore federated learning (FL).\n",
    "\n",
    "To recap, the core idea of FL is that many *devices* collaboratively train a single model, where each device has its own local private training data. Each device performs local training with its own data, and exchanges the weights of the NN model with all other devices via the *server*.\n",
    "\n",
    "You are one participant in an FL system that comprises all participating students in this lab.\n",
    "\n",
    "This excercise comprises two parts.\n",
    "* First, we will implement decentralized single-device training, i.e., no collaboration between devices. This will serve as a baseline to compare FL to.\n",
    "* Second, we will implement actual FL, where all participants collaboratively train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7241e36-23e2-4ce4-9d97-8ce24e923c43",
   "metadata": {},
   "source": [
    "## Part 1: Decentralized single-device training\n",
    "\n",
    "We start with the data. Therefore, we randomly distribute the CIFAR-10 dataset among all participants. This is already implemented in the helper functions in device_data. It divides the dataset into `total_clients` parts and returns the part with the number `client_id`.\n",
    "\n",
    "We also make use of test data. This is usually not available in FL. However, we still use it to test the model quality. Of course, the test data must not be used for training -- only testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6147e564-3e31-469d-af14-3d7c95a078cf",
   "metadata": {},
   "source": [
    "Adjust the following constants to the participants in the lab. Each participant is one client. Make sure that you use a different *CLIENT_ID*, each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3535eb2-c3e5-4e88-87c6-3f2bd44ff281",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_CLIENTS = 7  # number of participants in the lab\n",
    "CLIENT_ID = 2  # between 0 and TOTAL_CLIENTS-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76aa6d0f-8b95-4763-b001-2babbba0bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/cifar-10-python.tar.gz\n",
      "Extracting data/cifar-10-python.tar.gz to data/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import device_data\n",
    "\n",
    "training_dataset = device_data.get_client_training_data(CLIENT_ID, TOTAL_CLIENTS)\n",
    "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=16)\n",
    "test_dataset = device_data.get_test_data()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485fdea9-e0f7-412a-9528-2f17b334d02e",
   "metadata": {},
   "source": [
    "You are already familiar with training an NN in PyTorch. We want to train a CifarNet with your part of the training data.\n",
    "\n",
    "**Your Task:**\n",
    "- Create a instance of CifarNet, define the optimizer and the criteron. For the optimizer use `torch.optim.SGD` (https://pytorch.org/docs/stable/generated/torch.optim.SGD.html) , for the loss use criterion use `torch.nn.CrossEntropyLoss`. Use a learning rate of `0.001` and a momentum of `0.9`\n",
    "- implement the function train that trains the model CifarNet. The function `train` takes the model (an instance), the optimizer, an optimization criterion, a trainloader, and a device (either `cpu` or `cuda` as input)\n",
    "    - Firstly, set the model in training mode, load the model on the device. Secondly, push the `inputs` and `targets` to the device.\n",
    "    - Inside the batch loader loop, set the grads of the optimizer to zero (`.zero_grad()`) and push the inputs into the model. After that, calculate the loss and call backward on the loss. Lastly, apply the optimizer step.\n",
    "- Implement the function test that tests the model CifarNet, The function `test` takes the model (an instance), a testloader, and the device as input. The function returns the accuracy.\n",
    "    - Set the model into evaluation mode, for each batch calculate the number of correct detected and all detections.\n",
    "    - Return the accuracy (fraction of correct detected and all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebfe3586-4082-4a70-b387-a9546c673f43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/10: accuracy (0.48)                                                    \n",
      "Epoch  2/10: accuracy (0.52)                                                    \n",
      "Epoch  3/10: accuracy (0.54)                                                    \n",
      "Epoch  4/10: accuracy (0.57)                                                    \n",
      "Epoch  5/10: accuracy (0.57)                                                    \n",
      "Epoch  6/10: accuracy (0.57)                                                    \n",
      "Epoch  7/10: accuracy (0.58)                                                    \n",
      "Epoch  8/10: accuracy (0.57)                                                    \n",
      "Epoch  9/10: accuracy (0.58)                                                    \n",
      "Epoch 10/10: accuracy (0.58)                                                    \n"
     ]
    }
   ],
   "source": [
    "# this reaches <70% with 4 clients\n",
    "\n",
    "from models.cifarnet import CifarNet\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "device = 'cuda'\n",
    "epochs = 10\n",
    "\n",
    "#create a model instance and define loss and optimizer criterion\n",
    "#-to-be-done-by-student-------------\n",
    "model = CifarNet()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "#-----------------------------------\n",
    "\n",
    "def train(model, optimizer, criterion, trainloader, device='cpu'):\n",
    "    #-to-be-done-by-student---------\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    #-------------------------------\n",
    "    for _, (inputs, targets) in enumerate(tqdm(trainloader, ncols=80,\n",
    "                                               file=sys.stdout, desc=\"Training\", leave=False)):\n",
    "        \n",
    "        #-to-be-done-by-student----\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #--------------------------\n",
    "\n",
    "def test(model, testloader, device='cpu'):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    #-to-be-done-by-student---------\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    #-------------------------------\n",
    "    for _, (inputs, targets) in enumerate(tqdm(testloader, ncols=80,\n",
    "                                               file=sys.stdout, desc=\"Testing\", leave=False)):\n",
    "        #-to-be-done-by-student----\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        num_correct += sum(outputs.argmax(dim=1) == targets)\n",
    "        num_samples += len(targets)\n",
    "        #--------------------------\n",
    "        \n",
    "    return num_correct / num_samples\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(model, optimizer, criterion, train_loader, device=device)\n",
    "    accuracy = test(model, test_loader, device=device)\n",
    "    print(f'Epoch {epoch+1:2d}/{epochs:2d}: accuracy ({accuracy:.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-bachelor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
