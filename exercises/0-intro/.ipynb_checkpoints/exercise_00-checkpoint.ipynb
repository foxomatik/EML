{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5414047f-c2e5-4b51-a4bf-7b6b9c562a19",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Embedded ML Lab - Excercise 0 - Intro Pytorch\n",
    "\n",
    "* Documentation Pytorch: https://pytorch.org/docs/stable/index.html\n",
    "* Documentation Matplotlib: https://matplotlib.org/stable/contents.html\n",
    "\n",
    "### Tensor basics\n",
    "`PyTorch` uses _pytorch_ _tensors_ to store N-dimensional data similar to NumPy or Matlab. Torch tensors support a variety of matrix or vector operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32ca05e2-f9c9-4703-b923-28f02bb337f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15,  9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.rand(1).to('cuda') #initialize cuda context (might take a while)\n",
    "x = torch.tensor([5,3]) #create variable\n",
    "y = torch.tensor([3,3])\n",
    "\n",
    "z = x * y #point-wise multiplication of two variables \n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e9f788-ce37-4a53-a1e1-aa8fd34db305",
   "metadata": {},
   "source": [
    "Also, there are several methods to initialize tensors like `torch.ones / torch.zeros / torch.randn`   \n",
    "We can get the shape of a tensor by calling `size` on a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b85c810-8ee9-4fbc-b520-47ba10a65a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10, 5])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones((10,10,5)) # creates a 3-dimensional tensor with ones with size [10,10,5]\n",
    "rand = torch.randn((4,4)) # creates an 2-dimensional random tensor with size [4,4]\n",
    "\n",
    "print(ones.size()) # returns a python list with dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f828aaec-cb84-4b16-a527-3902bc9f8a15",
   "metadata": {},
   "source": [
    "Pytorch tensors can also have different datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d291bc8a-3c07-4d84-b226-e890f923290a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((10,10), dtype=torch.int) #inits a tensor with ones as int\n",
    "torch.ones((10,10), dtype=torch.float) #inits a tensor with ones as float (standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c838ef-d685-4021-b9bb-6fd50b6352b0",
   "metadata": {},
   "source": [
    "Similar to NumPy or Matlab we can also slice tensors with indices (NumPy Indexing: https://numpy.org/doc/stable/reference/arrays.indexing.html)   \n",
    "Slicing is equivalent to a torch.view. As the name suggests, this does not change the underlying storage or create a copy, meaning if we change the data, all associated views also show the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abff0483-bd54-4218-9c6d-cd2cc4660ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of a: torch.Size([5])\n",
      "tensor([3.1400, 3.1400, 3.1400, 3.1400, 3.1400])\n",
      "tensor([3.1400, 3.1400, 3.1400, 3.1400, 3.1400])\n",
      "tensor([7.1100, 7.1100, 7.1100, 7.1100, 7.1100])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones((10,10,5)) # creates a 3-dimensional tensor with ones with size [10,10,5]\n",
    "a = ones[0:5,0,0] # we create a view by slicing out index 0,1,2,3,4 from the first dimension and use : to slice all indices for dimension 2 and 3\n",
    "print(f\"Size of a: {a.size()}\")\n",
    "\n",
    "ones[0:5,:,:] = 3.14 \n",
    "print(a)\n",
    "b = ones.clone()[0:5,0,0] #cloning a tensor creates an independent copy\n",
    "ones[0:5,:,:] = 7.11\n",
    "print(b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fdf1fa-61a6-47b4-b613-344f6249c42d",
   "metadata": {},
   "source": [
    "Other usefull tensor operations are `flatten()`, `sum()`, `max()`, `min()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13c264c0-3ce1-418b-b626-643af4bcd679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a: torch.Size([10, 10, 10]), Shape of a_flattened: torch.Size([1000])\n",
      "Sum: tensor([100., 100., 100., 100., 100., 100., 100., 100., 100., 100.])\n",
      "Sum: 1000.0\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((10,10,10))\n",
    "a_flattened = a.flatten()\n",
    "print(f\"Shape of a: {a.size()}, Shape of a_flattened: {a_flattened.size()}\")\n",
    "sum_of_a = a.sum(dim=(0,1)) # sum of dimens 0 and 1 \n",
    "print(f\"Sum: {sum_of_a}\")\n",
    "sum_of_a = a.sum(dim=(0,1,2)) #sum_of_all_entries\n",
    "print(f\"Sum: {sum_of_a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3d3890-8d52-4c95-a500-2780fae86f40",
   "metadata": {},
   "source": [
    "A very special property of pytorch tensors is that they can be pushed to a device (a GPU) and operations can be done on a GPU. This can speedup operations dramatically, if the required operations are parallelizable.    \n",
    "We therefore first check if pytorch can reach the Jetsons' GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11d2bb31-e22d-4cf1-99f2-98bf17f0616e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available:        yes\n",
      "tensor(nan)\n",
      "2.81 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "tensor(9.1357, device='cuda:0')\n",
      "14 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "tensor(nan)\n",
      "14.2 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "tensor(8.6432, device='cuda:0')\n",
      "2.72 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(f'CUDA available:        {[\"no\", \"yes\"][torch.cuda.is_available()]}')\n",
    "\n",
    "a = torch.zeros((10**4, 10**4))\n",
    "b = torch.zeros((10**4, 10**4))\n",
    "\n",
    "def f(device, n, k):\n",
    "    x = torch.randn(n, n, dtype=torch.float32, device=device)\n",
    "    for _ in range(k):\n",
    "        x = torch.matmul(x, x)\n",
    "        x = (x - x.mean()) / x.std()\n",
    "    return x.max()\n",
    "\n",
    "n = 256\n",
    "k = 100\n",
    "\n",
    "%timeit -n 1 -r 1 print(f('cpu',  n, k))\n",
    "%timeit -n 1 -r 1 print(f('cuda', n, k))\n",
    "%timeit -n 1 -r 1 print(f('cpu',  4*n, k))\n",
    "%timeit -n 1 -r 1 print(f('cuda', 4*n, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4092e33d-77d9-4203-8546-3af85181e4e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "PyTorch tensors (data/nn-weights) can also be stored and loaded from disk.   \n",
    "We load a sample from the MNIST dataset, which is stored as \"mnist_sample.pt\" on the disk.\n",
    "The MNIST Dataset consists of images of handwritten grayscale images with digits from `0-9`\n",
    "* This can be done by using `torch.load(\"filename\")`. Similarly, we can store tensors`toch.store(tensor, \"filename\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df9bb5b-40c2-49d5-aaf6-4a3aa046d4ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "mnist_sample = torch.load(\"mnist_sample.pt\") #this loads a 28 by 28 pixel image from the MNSIT dataset\n",
    "print(mnist_sample.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e006552a-dae6-4d98-8cce-7ce64ac57b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pillow\n",
      "  Downloading pillow-10.4.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 7.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pillow\n",
      "Successfully installed pillow-10.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43b7dd30-19b3-492f-bdc0-20d93cfa17b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3ac77580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(mnist_sample[:,:], cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805918da-ca53-4b07-8eb8-fdcd9b100f24",
   "metadata": {},
   "source": [
    "### Pytorch Modules\n",
    "\n",
    "PyTorch modules are the base classes of neural networks in PyTorch. All modules we define should inherit from `torch.nn.Module`. Modules can also contain other Modules, allowing nesting.    \n",
    "A tensor can be defined as a `Parameter` of a module.\n",
    "Every module has a forward path defined. We add the paramter to our input and return the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e556d26d-bd10-4c01-a81b-3c317cc2349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class AddConstant(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AddConstant, self).__init__()\n",
    "        self.add_value = nn.parameter.Parameter(torch.tensor(5), requires_grad=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x + self.add_value\n",
    "        return y\n",
    "    \n",
    "addc = AddConstant() #we create a new addValue istance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0339d4c7-12d9-4cc9-ad46-844be03ddbcf",
   "metadata": {},
   "source": [
    "Our AddValue module has several inherited functionality\n",
    "* The forward pass can be called by either using the call function `addv(5)` or by directly calling the forward function `addv.forward(5)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fce9610-341e-407e-85c8-f11f19840ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 10\n",
      "[('add_value', Parameter containing:\n",
      "tensor(5))]\n"
     ]
    }
   ],
   "source": [
    "y = addc(5)\n",
    "y = addc.forward(5)\n",
    "print(f\"Result: {y}\")\n",
    "print(list(addc.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7c17ea-f386-4d07-bbf7-63c550e2aae9",
   "metadata": {},
   "source": [
    "We can load and set so-called 'state_dicts' from modules, containing all parameters (a.k.a NN weights).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bdf7db1-b7bf-40a4-ac48-48e42b0d4d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('add_value', tensor(5))])\n",
      "Result: 9\n"
     ]
    }
   ],
   "source": [
    "state_dict = addc.state_dict()\n",
    "print(state_dict)\n",
    "state_dict['add_value'] = torch.tensor(4)\n",
    "addc.load_state_dict(state_dict)\n",
    "print(f\"Result: {addc.forward(5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73ac87-508b-44cb-b8de-100a9a3c5b79",
   "metadata": {},
   "source": [
    "Modules can also be pushed to the GPU for calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee84a7a3-cc48-4b0d-8bd7-d3df2303d862",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "addc.to('cpu')\n",
    "y = addc(torch.tensor(5, device='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed02c67-2c53-4953-987d-bd83da9586ec",
   "metadata": {},
   "source": [
    "Functions that do not have parameters can be found in `torch.nn.functional`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9d47d08-adf6-4bb2-ad9a-6db76b4e928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "result = F.relu(torch.ones(1))\n",
    "result = F.max_pool2d(torch.ones((10,10,10)), kernel_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583b539-4231-460c-984c-af048dd08ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
