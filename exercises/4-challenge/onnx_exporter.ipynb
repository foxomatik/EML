{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfu8stbQUrig"
      },
      "source": [
        "# Exporting TinyYoloV2 to ONNX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho6ISOikU7IO"
      },
      "source": [
        "## Prepare Workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFwl58deVT4B"
      },
      "source": [
        "### Define Google Colab Flag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KXOV0L3_Vd5T"
      },
      "outputs": [],
      "source": [
        "GOOGLE_COLAB = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIbSd80CVvim"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoGb75c63blH"
      },
      "outputs": [],
      "source": [
        "if GOOGLE_COLAB:\n",
        "    import os\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Check if Google Drive is already mounted\n",
        "    if not os.path.exists('/content/drive/My Drive'):\n",
        "        print(\"Mounting Google Drive...\")\n",
        "        drive.mount('/content/drive')\n",
        "    else:\n",
        "        print(\"Google Drive is already mounted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGb2-12sHuSW"
      },
      "source": [
        "### Set-up Directories & Install Libraires\n",
        "Create the directories needed and copy uploaded files into them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMlA8hKU93Vi"
      },
      "outputs": [],
      "source": [
        "!pip uninstall onnxconverter-common -y\n",
        "if GOOGLE_COLAB:\n",
        "    !pip install torchinfo\n",
        "    !pip install torchvision pillow\n",
        "    !pip install onnx\n",
        "    !pip install onnxscript\n",
        "    !pip install onnxruntime-gpu==1.19.0\n",
        "    !pip install onnxruntime-extensions\n",
        "    !pip install onnxconverter-common\n",
        "\n",
        "    !mkdir /content/data\n",
        "\n",
        "    !cp /content/drive/MyDrive/eml_challenge/data/person_indices.json /content/data\n",
        "    !cp -r /content/drive/MyDrive/eml_challenge/utils /content\n",
        "    !cp /content/drive/MyDrive/eml_challenge/tinyyolov2_fused.py /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzIVyeeGq_Sg"
      },
      "source": [
        "### Define Path to Weights and Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAiKUHurq_aS"
      },
      "outputs": [],
      "source": [
        "if GOOGLE_COLAB:\n",
        "    WEIGHTS_PATH = \"/content/drive/MyDrive/eml_challenge/weights/\"\n",
        "    MODELS_PATH = \"/content/drive/MyDrive/eml_challenge/\"\n",
        "else:\n",
        "    WEIGHTS_PATH = \"./\"\n",
        "    MODELS_PATH = \"./models/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCi-d3NlWeRl"
      },
      "source": [
        "### Append Directory Paths to System Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "75a9jpWp9WfF"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if GOOGLE_COLAB:\n",
        "    sys.path.append('/content')\n",
        "    sys.path.append('/content/data')\n",
        "    sys.path.append('/content/utils')\n",
        "    sys.path.append(WEIGHTS_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWzCwEErXfKE"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "idmHICjM9Vq8"
      },
      "outputs": [],
      "source": [
        "# Pytorch libraries\n",
        "import torch\n",
        "import torchinfo\n",
        "import torch.nn as nn\n",
        "\n",
        "# Other libraires\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import time\n",
        "\n",
        "# ONNX libraries\n",
        "import onnx\n",
        "import onnxruntime\n",
        "from onnxconverter_common import float16\n",
        "\n",
        "# EML libraires\n",
        "from tinyyolov2_fused import FusedTinyYoloV2\n",
        "from utils.dataloader_v2 import VOCDataset\n",
        "from utils.ap import precision_recall_levels, ap, display_roc\n",
        "from utils.yolo import nms, filter_boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyeriPqUMK3u"
      },
      "source": [
        "## Define ONNX Export Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULRn5fGAC3wL"
      },
      "source": [
        "### Define export_to_onnx Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UCpYhy7nC8O8"
      },
      "outputs": [],
      "source": [
        "def export_to_onnx(model, onnx_path):\n",
        "    model.to(device=torch_device)\n",
        "    model.eval()\n",
        "\n",
        "    # Define ONNX model input shape\n",
        "    dummy_input = torch.empty(TEST_BATCH_SIZE, IMAGE_CHANNELS, IMAGE_LENGTH, IMAGE_WIDTH, device=torch_device)\n",
        "\n",
        "    # Export model using TorchScript based ONNX exporter\n",
        "    torch.onnx.export(model,                     # model being run\n",
        "                    dummy_input,                 # model input (or a tuple for multiple inputs)\n",
        "                    onnx_path,                   # where to save the model (can be a file or file-like object)\n",
        "                    export_params=True,          # store the trained parameter weights inside the model file\n",
        "                    verbose=False,               # print information to stdout\n",
        "                    opset_version=OPSET_VERSION, # the ONNX version to export the model to\n",
        "                    input_names = ['input'],     # the model's input names\n",
        "                    output_names = ['output'],   # the model's output names\n",
        "                    dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
        "                                  'output' : {0 : 'batch_size'}})\n",
        "\n",
        "    # Load and check if ONNX network was saved correclty\n",
        "    onnx_net = onnx.load(onnx_path)\n",
        "    onnx.checker.check_model(onnx_net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqg-oNjCIS1U"
      },
      "source": [
        "### Define convert_onnx_fp32_to_fp16 Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ThAMkrL-IZAP"
      },
      "outputs": [],
      "source": [
        "def convert_onnx_fp32_to_fp16(onnx_path, onnx_path_fp16):\n",
        "    model = onnx.load(onnx_path)\n",
        "    model_fp16 = float16.convert_float_to_float16(model)\n",
        "    onnx.save(model_fp16, onnx_path_fp16)\n",
        "\n",
        "    # Load and check if ONNX network was saved correclty\n",
        "    onnx_net = onnx.load(onnx_path_fp16)\n",
        "    onnx.checker.check_model(onnx_net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keDySKlVWq-p"
      },
      "source": [
        "## Define Precision and Latency Measurement Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dsg14u0OPX_c"
      },
      "source": [
        "### Define measure_pytorch_latency Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ZXMCYjoRPsCn"
      },
      "outputs": [],
      "source": [
        "def measure_pytorch_latency(model):\n",
        "    model.to(torch_device)\n",
        "    t_start = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _, (input, _) in tqdm.tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            input = input.to(torch_device)\n",
        "            model.forward(input)\n",
        "\n",
        "    t_end  = time.time()\n",
        "    t_diff = t_end - t_start\n",
        "\n",
        "    return t_diff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aawfzSEnJBkS"
      },
      "source": [
        "### Define measure_pytorch_f16_latency() Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "SAqHtH1WJJ46"
      },
      "outputs": [],
      "source": [
        "def measure_pytorch_f16_latency(model):\n",
        "    model.to(device=torch_device, dtype=torch.float16)\n",
        "    t_start = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, (input, _) in tqdm.tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            input = input.to(torch_device, dtype=torch.float16)\n",
        "            # with torch.amp.autocast(device_type='cuda:0', enabled=True, dtype=torch.float16):\n",
        "            model.forward(input)\n",
        "\n",
        "    t_end  = time.time()\n",
        "    t_diff = t_end - t_start\n",
        "\n",
        "    return t_diff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3XhaxZ9kO2R"
      },
      "source": [
        "### Define measure_onnx_latency Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pTs5Z2hKkUfs"
      },
      "outputs": [],
      "source": [
        "def measure_onnx_latency(onnx_session):\n",
        "    ort_output = torch.empty([TEST_BATCH_SIZE, OUTPUT_DIMENSON_1, OUTPUT_DIMENSON_2, OUTPUT_DIMENSON_3, OUTPUT_DIMENSON_4]\n",
        "                             , dtype=torch.float32\n",
        "                             , device=torch_device)\n",
        "\n",
        "    binding = onnx_session.io_binding()\n",
        "\n",
        "    binding.bind_output(\n",
        "    name='output',\n",
        "    device_type='cuda',\n",
        "    device_id=0,\n",
        "    element_type=np.float32,\n",
        "    shape=tuple(ort_output.shape),\n",
        "    buffer_ptr=ort_output.data_ptr(),\n",
        "    )\n",
        "\n",
        "    t_start = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (input, target) in tqdm.tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            if torch.cuda.is_available():\n",
        "                input = input.to(torch_device)\n",
        "\n",
        "                binding.bind_input(\n",
        "                    name='input',\n",
        "                    device_type='cuda',\n",
        "                    device_id=0,\n",
        "                    element_type=np.float32,\n",
        "                    shape=tuple(input.shape),\n",
        "                    buffer_ptr=input.data_ptr(),\n",
        "                )\n",
        "\n",
        "                onnx_session.run_with_iobinding(binding)\n",
        "            else:\n",
        "                input  = input.to(torch_device)\n",
        "                ort_input  = {onnx_session.get_inputs()[0].name: to_numpy(input)}\n",
        "                ort_output = onnx_session.run(None, ort_input)[0]\n",
        "                ort_output = torch.from_numpy(ort_output)\n",
        "\n",
        "    t_end  = time.time()\n",
        "    t_diff = t_end - t_start\n",
        "\n",
        "    return t_diff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESuLwZrqOzbR"
      },
      "source": [
        "### Define measure_onnx_fp16_latency Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xD5rNTOjO4jm"
      },
      "outputs": [],
      "source": [
        "def measure_onnx_fp16_latency(onnx_session):\n",
        "    ort_output = torch.empty([TEST_BATCH_SIZE, OUTPUT_DIMENSON_1, OUTPUT_DIMENSON_2, OUTPUT_DIMENSON_3, OUTPUT_DIMENSON_4]\n",
        "                             , dtype=torch.float16\n",
        "                             , device=torch_device)\n",
        "\n",
        "    binding_fp16 = onnx_session.io_binding()\n",
        "\n",
        "    binding_fp16.bind_output(\n",
        "    name='output',\n",
        "    device_type='cuda',\n",
        "    device_id=0,\n",
        "    element_type=np.float16,\n",
        "    shape=tuple(ort_output.shape),\n",
        "    buffer_ptr=ort_output.data_ptr(),\n",
        "    )\n",
        "\n",
        "    t_start = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (input, target) in tqdm.tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            if torch.cuda.is_available():\n",
        "                input = input.to(torch_device, dtype=torch.float16)\n",
        "\n",
        "                binding_fp16.bind_input(\n",
        "                    name='input',\n",
        "                    device_type='cuda',\n",
        "                    device_id=0,\n",
        "                    element_type=np.float16,\n",
        "                    shape=tuple(input.shape),\n",
        "                    buffer_ptr=input.data_ptr(),\n",
        "                )\n",
        "\n",
        "                onnx_session.run_with_iobinding(binding_fp16)\n",
        "            else:\n",
        "                input  = input.to(dtype=torch.float16)\n",
        "                ort_input  = {onnx_session.get_inputs()[0].name: to_numpy(input)}\n",
        "                ort_output = onnx_session.run(None, ort_input)[0]\n",
        "                ort_output = torch.from_numpy(ort_output)\n",
        "\n",
        "    t_end  = time.time()\n",
        "    t_diff = t_end - t_start\n",
        "\n",
        "    return t_diff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFUOyB4Am8p7"
      },
      "source": [
        "### Define measure_pytorch_avg_precision Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TS5amBO9m87L"
      },
      "outputs": [],
      "source": [
        "def measure_pytorch_avg_precision(model):\n",
        "    test_precision = []\n",
        "    test_recall = []\n",
        "\n",
        "    model.to(torch_device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (input, target) in tqdm.tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            input  = input.to(torch_device)\n",
        "            target = target.to(torch_device)\n",
        "            output = model(input, yolo=True)\n",
        "            output = filter_boxes(output, CONFIDENCE_THRESHOLD)\n",
        "            output = nms(output, NMS_THRESHOLD)\n",
        "            # Calculate precision and recall for each sample\n",
        "            for i in range(len(target)):\n",
        "                precision, recall = precision_recall_levels(target[i], output[i])\n",
        "                test_precision.append(precision)\n",
        "                test_recall.append(recall)\n",
        "\n",
        "    # Calculate average precision with collected samples\n",
        "    average_precision = ap(test_precision, test_recall)\n",
        "    # Plot ROC\n",
        "    display_roc(test_precision, test_recall)\n",
        "\n",
        "    return average_precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nqRh8-cPpUM"
      },
      "source": [
        "### Define measure_pytorch_fp16_avg_precision Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jkZ5L3thPuVf"
      },
      "outputs": [],
      "source": [
        "def measure_pytorch_fp16_avg_precision(model):\n",
        "    test_precision = []\n",
        "    test_recall = []\n",
        "\n",
        "    model.to(device=torch_device, dtype=torch.float16)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (input, target) in tqdm.tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            input  = input.to(device=torch_device, dtype=torch.float16)\n",
        "            target = target.to(device=torch_device, dtype=torch.float16)\n",
        "            output = model(input, yolo=True)\n",
        "            output = filter_boxes(output, CONFIDENCE_THRESHOLD)\n",
        "            output = nms(output, NMS_THRESHOLD)\n",
        "            # Calculate precision and recall for each sample\n",
        "            for i in range(len(target)):\n",
        "                precision, recall = precision_recall_levels(target[i], output[i])\n",
        "                test_precision.append(precision)\n",
        "                test_recall.append(recall)\n",
        "\n",
        "    # Calculate average precision with collected samples\n",
        "    average_precision = ap(test_precision, test_recall)\n",
        "    # Plot ROC\n",
        "    display_roc(test_precision, test_recall)\n",
        "\n",
        "    return average_precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKfFjSTlm9M8"
      },
      "source": [
        "### Define measure_onnx_avg_precision Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jnDqxUxCm9bW"
      },
      "outputs": [],
      "source": [
        "def measure_onnx_avg_precision(onnx_session):\n",
        "    test_precision = []\n",
        "    test_recall = []\n",
        "\n",
        "    ort_output = torch.empty([TEST_BATCH_SIZE, OUTPUT_DIMENSON_1, OUTPUT_DIMENSON_2, OUTPUT_DIMENSON_3, OUTPUT_DIMENSON_4]\n",
        "                             , dtype=torch.float32\n",
        "                             , device=torch_device)\n",
        "\n",
        "    binding = onnx_session.io_binding()\n",
        "\n",
        "    binding.bind_output(\n",
        "    name='output',\n",
        "    device_type='cuda',\n",
        "    device_id=0,\n",
        "    element_type=np.float32,\n",
        "    shape=tuple(ort_output.shape),\n",
        "    buffer_ptr=ort_output.data_ptr(),\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (input, target) in tqdm.tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            if torch.cuda.is_available():\n",
        "                input  = input.to(torch_device)\n",
        "                target = target.to(torch_device)\n",
        "\n",
        "                binding.bind_input(\n",
        "                    name='input',\n",
        "                    device_type='cuda',\n",
        "                    device_id=0,\n",
        "                    element_type=np.float32,\n",
        "                    shape=tuple(input.shape),\n",
        "                    buffer_ptr=input.data_ptr(),\n",
        "                )\n",
        "                onnx_session.run_with_iobinding(binding)\n",
        "                output = filter_boxes(ort_output, CONFIDENCE_THRESHOLD)\n",
        "                output = nms(output, NMS_THRESHOLD)\n",
        "            else:\n",
        "                ort_input  = {onnx_session.get_inputs()[0].name: to_numpy(input)}\n",
        "                ort_output = onnx_session.run(None, ort_input)[0]\n",
        "                ort_output = torch.from_numpy(ort_output)\n",
        "                output = filter_boxes(ort_output, CONFIDENCE_THRESHOLD)\n",
        "                output = nms(ort_output, NMS_THRESHOLD)\n",
        "            # Calculate precision and recall for each sample\n",
        "            for i in range(len(target)):\n",
        "                precision, recall = precision_recall_levels(target[i], output[i])\n",
        "                test_precision.append(precision)\n",
        "                test_recall.append(recall)\n",
        "\n",
        "    # Calculate average precision with collected samples\n",
        "    average_precision = ap(test_precision, test_recall)\n",
        "    # Plot ROC\n",
        "    display_roc(test_precision, test_recall)\n",
        "\n",
        "    return average_precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mkKyotGVALx"
      },
      "source": [
        "### Define measure_onnx_fp16_avg_precision Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LJmv5d7QVE4m"
      },
      "outputs": [],
      "source": [
        "def measure_onnx_fp16_avg_precision(onnx_session):\n",
        "    test_precision = []\n",
        "    test_recall = []\n",
        "\n",
        "    ort_output = torch.empty([TEST_BATCH_SIZE, OUTPUT_DIMENSON_1, OUTPUT_DIMENSON_2, OUTPUT_DIMENSON_3, OUTPUT_DIMENSON_4]\n",
        "                             , dtype=torch.float16\n",
        "                             , device=torch_device)\n",
        "    binding_fp16 = onnx_session.io_binding()\n",
        "\n",
        "    binding_fp16.bind_output(\n",
        "    name='output',\n",
        "    device_type='cuda',\n",
        "    device_id=0,\n",
        "    element_type=np.float16,\n",
        "    shape=tuple(ort_output.shape),\n",
        "    buffer_ptr=ort_output.data_ptr(),\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (input, target) in tqdm.tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "            if torch.cuda.is_available():\n",
        "                input  = input.to(device=torch_device, dtype=torch.float16)\n",
        "                target = target.to(device=torch_device, dtype=torch.float16)\n",
        "\n",
        "                binding_fp16.bind_input(\n",
        "                    name='input',\n",
        "                    device_type='cuda',\n",
        "                    device_id=0,\n",
        "                    element_type=np.float16,\n",
        "                    shape=tuple(input.shape),\n",
        "                    buffer_ptr=input.data_ptr(),\n",
        "                )\n",
        "                onnx_session.run_with_iobinding(binding_fp16)\n",
        "                output = filter_boxes(ort_output, CONFIDENCE_THRESHOLD)\n",
        "                output = nms(output, NMS_THRESHOLD)\n",
        "            else:\n",
        "                input  = input.to(dtype=torch.float16)\n",
        "                target = target.to(dtype=torch.float16)\n",
        "                print(f'Input shape: {input.shape}')\n",
        "\n",
        "                ort_input  = {onnx_session.get_inputs()[0].name: to_numpy(input)}\n",
        "                ort_output = onnx_session.run(None, ort_input)[0]\n",
        "                print(f'ort_output shape: {ort_output.shape}')\n",
        "                ort_output = torch.from_numpy(ort_output)\n",
        "                output = filter_boxes(ort_output, CONFIDENCE_THRESHOLD)\n",
        "                print(f'output shape after filter_boxes: {output[0].shape}')\n",
        "                output = nms(ort_output, NMS_THRESHOLD)\n",
        "                print(f'output shape after nms: {output[0].shape}')\n",
        "            # Calculate precision and recall for each sample\n",
        "            for i in range(len(target)):\n",
        "                precision, recall = precision_recall_levels(target[i], output[i])\n",
        "                test_precision.append(precision)\n",
        "                test_recall.append(recall)\n",
        "\n",
        "    # Calculate average precision with collected samples\n",
        "    average_precision = ap(test_precision, test_recall)\n",
        "    # Plot ROC\n",
        "    display_roc(test_precision, test_recall)\n",
        "\n",
        "    return average_precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y5mziL7WyxI"
      },
      "source": [
        "## Define Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWixVzm4M5Xn"
      },
      "source": [
        "### Define to_numpy Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZFFovoNeM5l3"
      },
      "outputs": [],
      "source": [
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGRCD6bkc9rp"
      },
      "source": [
        "## Define Global Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTtlnkl6HDKl"
      },
      "source": [
        "### Define Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7lbNFxlUHCrZ"
      },
      "outputs": [],
      "source": [
        "# Image Size\n",
        "IMAGE_LENGTH         = 320\n",
        "IMAGE_WIDTH          = 320\n",
        "IMAGE_CHANNELS       = 3\n",
        "# Output Size\n",
        "OUTPUT_DIMENSON_1    = 5\n",
        "OUTPUT_DIMENSON_2    = 10\n",
        "OUTPUT_DIMENSON_3    = 10\n",
        "OUTPUT_DIMENSON_4    = 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-5SXKE_FqbU"
      },
      "source": [
        "### Define Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eVXKrR3_FskG"
      },
      "outputs": [],
      "source": [
        "# Thresholds\n",
        "CONFIDENCE_THRESHOLD = 0.0\n",
        "NMS_THRESHOLD        = 0.5\n",
        "# Batch size\n",
        "TEST_BATCH_SIZE      = 1\n",
        "# ONNX Version\n",
        "OPSET_VERSION        = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9NPp8c8pxxG"
      },
      "source": [
        "### Define Measurement Cases Flags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "JuYaJP5Kp0M_"
      },
      "outputs": [],
      "source": [
        "# Latency Measurements\n",
        "PYTORCH_LATENCY_MEASUREMENT        = True\n",
        "PYTORCH_LATENCY_FP16_MEASUREMENT   = True\n",
        "ONNX_LATENCY_MEASUREMENT           = True\n",
        "ONNX_LATENCY_FP16_MEASUREMENT      = True\n",
        "\n",
        "# Precision Measurements\n",
        "PYTORCH_PRECISION_MEASUREMENT      = False\n",
        "PYTORCH_FP16_PRECISION_MEASUREMENT = False\n",
        "ONNX_PRECISION_MEASUREMENT         = False\n",
        "ONNX_PRECISION_FP16_MEASUREMENT    = False\n",
        "\n",
        "DISCONNECT_RUN_TIME = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HMJvI6UExHd"
      },
      "source": [
        "### Define dataLoader, device & models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BgrPAPBE5Q8"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch_device = torch.device('cuda:0')\n",
        "    provider     = [\"CUDAExecutionProvider\"]\n",
        "    sd = torch.load(WEIGHTS_PATH + \"fused_voc_fine_tuned.pt\", weights_only=True)\n",
        "    print(\"Using GPU\")\n",
        "else:\n",
        "    torch_device = torch.device('cpu')\n",
        "    provider     = [\"CPUExecutionProvider\"]\n",
        "    sd = torch.load(WEIGHTS_PATH + \"fused_voc_fine_tuned.pt\", weights_only=True, map_location=torch_device)\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "test_dataset = VOCDataset(root=\"/content/data\", year=\"2012\", image_set='val', only_person=True) # Contains 2232 pictures\n",
        "test_loader  = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
        "\n",
        "net = FusedTinyYoloV2(num_classes=1)\n",
        "net_fp16 = FusedTinyYoloV2(num_classes=1)\n",
        "\n",
        "net.load_state_dict(sd)\n",
        "net_fp16.load_state_dict(sd)\n",
        "\n",
        "net_fp16.to(device=torch_device, dtype=torch.float16)\n",
        "\n",
        "onnx_filepath      = MODELS_PATH + \"tiny_yolo.onnx\"\n",
        "onnx_filepath_fp16 = MODELS_PATH + \"tiny_yolo_fp16.onnx\"\n",
        "\n",
        "export_to_onnx(model=net, onnx_path=onnx_filepath)\n",
        "convert_onnx_fp32_to_fp16(onnx_path=onnx_filepath, onnx_path_fp16=onnx_filepath_fp16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-j4dYNvk0f6"
      },
      "source": [
        "### Define ONNX Inference Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ34IegKkxKO"
      },
      "outputs": [],
      "source": [
        "# Define Inference Session Options\n",
        "session_options = onnxruntime.SessionOptions()\n",
        "session_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "\n",
        "# Define Inference Session for 32 Bit Float\n",
        "ort_session = onnxruntime.InferenceSession(onnx_filepath, providers=provider, sess_options=session_options)\n",
        "# Define Inference Session for 16 Bit Float\n",
        "ort_session_fp16 = onnxruntime.InferenceSession(onnx_filepath_fp16, providers=provider, sess_options=session_options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "248QvLkWEs28"
      },
      "source": [
        "## Execute Workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKBtrvoAem7-"
      },
      "source": [
        "### Execute Measurements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKfOeMVIev91",
        "outputId": "3375599a-f2c1-4354-bf64-406ce83a08b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**************************************************************************************\n",
            "Measuring Pytorch Latency...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2232/2232 [00:16<00:00, 137.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pytorch Latency: 16.194 seconds\n",
            "**************************************************************************************\n",
            "\n",
            "**************************************************************************************\n",
            "Measuring Pytorch FP16 Latency...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2232/2232 [00:16<00:00, 134.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pytorch FP16 Latency: 16.594 seconds\n",
            "**************************************************************************************\n",
            "\n",
            "**************************************************************************************\n",
            "Measuring ONNX Latency...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2232/2232 [00:22<00:00, 99.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX Latency: 22.349 seconds\n",
            "**************************************************************************************\n",
            "\n",
            "**************************************************************************************\n",
            "Measuring ONNX FP16 Latency...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2232/2232 [00:19<00:00, 111.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX FP16 Latency: 19.979 seconds\n",
            "**************************************************************************************\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from ast import mod\n",
        "if PYTORCH_LATENCY_MEASUREMENT:\n",
        "    print(\"**************************************************************************************\")\n",
        "    print(\"Measuring Pytorch Latency...\")\n",
        "    pytorch_latency = measure_pytorch_latency(model=net)\n",
        "    print(f\"Pytorch Latency: {pytorch_latency:.5} seconds\")\n",
        "    print(\"**************************************************************************************\\n\")\n",
        "\n",
        "if PYTORCH_LATENCY_FP16_MEASUREMENT:\n",
        "    print(\"**************************************************************************************\")\n",
        "    print(\"Measuring Pytorch FP16 Latency...\")\n",
        "    pytorch_latency = measure_pytorch_f16_latency(model=net_fp16)\n",
        "    print(f\"Pytorch FP16 Latency: {pytorch_latency:.5} seconds\")\n",
        "    print(\"**************************************************************************************\\n\")\n",
        "\n",
        "if ONNX_LATENCY_MEASUREMENT:\n",
        "    print(\"**************************************************************************************\")\n",
        "    print(\"Measuring ONNX Latency...\")\n",
        "    onnx_latency = measure_onnx_latency(onnx_session=ort_session)\n",
        "    print(f\"ONNX Latency: {onnx_latency:.5} seconds\")\n",
        "    print(\"**************************************************************************************\\n\")\n",
        "\n",
        "if ONNX_LATENCY_FP16_MEASUREMENT:\n",
        "    print(\"**************************************************************************************\")\n",
        "    print(\"Measuring ONNX FP16 Latency...\")\n",
        "    onnx_latency = measure_onnx_fp16_latency(onnx_session=ort_session_fp16)\n",
        "    print(f\"ONNX FP16 Latency: {onnx_latency:.5} seconds\")\n",
        "    print(\"**************************************************************************************\\n\")\n",
        "\n",
        "if PYTORCH_PRECISION_MEASUREMENT:\n",
        "    print(\"**************************************************************************************\")\n",
        "    print(\"Measuring Pytorch Average Precision...\")\n",
        "    pytorch_avg_precision = measure_pytorch_avg_precision(model=net)\n",
        "    print(f\"Pytorch Average Precision: {pytorch_avg_precision:.5}\")\n",
        "    print(\"**************************************************************************************\\n\")\n",
        "\n",
        "if PYTORCH_FP16_PRECISION_MEASUREMENT:\n",
        "    print(\"**************************************************************************************\")\n",
        "    print(\"Measuring Pytorch FP16 Average Precision...\")\n",
        "    pytorch_avg_precision = measure_pytorch_fp16_avg_precision(model=net_fp16)\n",
        "    print(f\"Pytorch FP16 Average Precision: {pytorch_avg_precision:.5}\")\n",
        "    print(\"**************************************************************************************\\n\")\n",
        "\n",
        "if ONNX_PRECISION_MEASUREMENT:\n",
        "    print(\"**************************************************************************************\")\n",
        "    print(\"Measuring ONNX Average Precision...\")\n",
        "    onnx_avg_precision = measure_onnx_avg_precision(onnx_session=ort_session)\n",
        "    print(f\"ONNX Average Precision: {onnx_avg_precision:.5}\")\n",
        "    print(\"**************************************************************************************\\n\")\n",
        "\n",
        "if ONNX_PRECISION_FP16_MEASUREMENT:\n",
        "    print(\"**************************************************************************************\")\n",
        "    print(\"Measuring ONNX FP16 Average Precision...\")\n",
        "    onnx_avg_precision = measure_onnx_fp16_avg_precision(onnx_session=ort_session_fp16)\n",
        "    print(f\"ONNX FP16 Average Precision: {onnx_avg_precision:.5}\")\n",
        "    print(\"**************************************************************************************\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOQB5eyuCqmo"
      },
      "source": [
        "### Disconnect runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZrHhO7GCqvS"
      },
      "outputs": [],
      "source": [
        "if GOOGLE_COLAB and DISCONNECT_RUN_TIME:\n",
        "    from google.colab import runtime\n",
        "    runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
