{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download and Filter The COCO Dataset"
      ],
      "metadata": {
        "id": "KTM_22wxuDkm"
      },
      "id": "KTM_22wxuDkm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Workspace"
      ],
      "metadata": {
        "id": "9NpZQJ23ueSs"
      },
      "id": "9NpZQJ23ueSs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Google Colab Flag"
      ],
      "metadata": {
        "id": "FFwl58deVT4B"
      },
      "id": "FFwl58deVT4B"
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_COLAB = True"
      ],
      "metadata": {
        "id": "KXOV0L3_Vd5T"
      },
      "execution_count": 1,
      "outputs": [],
      "id": "KXOV0L3_Vd5T"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive"
      ],
      "metadata": {
        "id": "oIbSd80CVvim"
      },
      "id": "oIbSd80CVvim"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eoGb75c63blH",
        "outputId": "151ce518-be11-4d16-c7a1-a102c31b942b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if GOOGLE_COLAB:\n",
        "    import os\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Check if Google Drive is already mounted\n",
        "    if not os.path.exists('/content/drive/My Drive'):\n",
        "        print(\"Mounting Google Drive...\")\n",
        "        drive.mount('/content/drive')\n",
        "    else:\n",
        "        print(\"Google Drive is already mounted.\")"
      ],
      "id": "eoGb75c63blH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGb2-12sHuSW"
      },
      "source": [
        "### Set-up Directories & Install Libraires\n",
        "Create the directories needed and copy uploaded files into them"
      ],
      "id": "MGb2-12sHuSW"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "oMlA8hKU93Vi"
      },
      "outputs": [],
      "source": [
        "if GOOGLE_COLAB:\n",
        "    !mkdir -p /content/data\n",
        "\n",
        "    !cp -r /content/drive/MyDrive/eml_challenge/utils /content\n",
        "    !cp /content/drive/MyDrive/eml_challenge/data/COCO/coco_train2017_person.json /content/data/\n",
        "    !cp /content/drive/MyDrive/eml_challenge/data/COCO/coco_val2017_person.json /content/data/"
      ],
      "id": "oMlA8hKU93Vi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzIVyeeGq_Sg"
      },
      "source": [
        "### Define Path to Dataset"
      ],
      "id": "VzIVyeeGq_Sg"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kAiKUHurq_aS"
      },
      "outputs": [],
      "source": [
        "if GOOGLE_COLAB:\n",
        "    TEMP_DATA_PATH = \"/content/data/\"\n",
        "    DATA_PATH      = \"/content/drive/MyDrive/eml_challenge/data/COCO/\""
      ],
      "id": "kAiKUHurq_aS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCi-d3NlWeRl"
      },
      "source": [
        "### Append Directory Paths to System Path"
      ],
      "id": "SCi-d3NlWeRl"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "75a9jpWp9WfF"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if GOOGLE_COLAB:\n",
        "    sys.path.append('/content')\n",
        "    sys.path.append('/content/utils')\n",
        "    sys.path.append(TEMP_DATA_PATH)"
      ],
      "id": "75a9jpWp9WfF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWzCwEErXfKE"
      },
      "source": [
        "### Import Libraries"
      ],
      "id": "kWzCwEErXfKE"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "idmHICjM9Vq8"
      },
      "outputs": [],
      "source": [
        "# Libraires\n",
        "from tqdm import tqdm\n",
        "import urllib.request\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "import json"
      ],
      "id": "idmHICjM9Vq8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Dataset Filtering Function"
      ],
      "metadata": {
        "id": "py-0-4rlyAvz"
      },
      "id": "py-0-4rlyAvz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define delete_non_person_images Function"
      ],
      "metadata": {
        "id": "ci53qfT7yS86"
      },
      "id": "ci53qfT7yS86"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "IhootX84yZEr"
      },
      "outputs": [],
      "source": [
        "def delete_non_person_images(annotations_file, images_dir):\n",
        "    \"\"\"\n",
        "    Deletes all images from the directory that are not referenced in the JSON file for the \"person\" category.\n",
        "\n",
        "    Args:\n",
        "        annotations_file (str): Path to the filtered JSON annotations file.\n",
        "        images_dir (str): Directory containing the COCO images.\n",
        "    \"\"\"\n",
        "    # Load the annotations file\n",
        "    with open(annotations_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Get the list of image IDs that contain the \"person\" category\n",
        "    person_image_ids = {image['id'] for image in data['images']}\n",
        "\n",
        "    # Get the set of image file names to keep\n",
        "    person_image_filenames = {image['file_name'] for image in data['images']}\n",
        "\n",
        "    # Iterate through the images in the directory\n",
        "    print(\"Scanning images in the directory...\")\n",
        "    for image_file in tqdm(os.listdir(images_dir)):\n",
        "        # If the file is not in the set of person image filenames, delete it\n",
        "        if image_file not in person_image_filenames:\n",
        "            file_path = os.path.join(images_dir, image_file)\n",
        "            try:\n",
        "                os.remove(file_path)\n",
        "                #tqdm.write(f\"Deleted: {file_path}\")\n",
        "            except Exception as e:\n",
        "                tqdm.write(f\"Error deleting {file_path}: {e}\")\n",
        "\n",
        "    print(\"Completed: All non-person images have been deleted.\")"
      ],
      "id": "IhootX84yZEr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execute Workspace"
      ],
      "metadata": {
        "id": "skgR65anymwQ"
      },
      "id": "skgR65anymwQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download & Unpack Training Dataset"
      ],
      "metadata": {
        "id": "KyvjmpFyyqnq"
      },
      "id": "KyvjmpFyyqnq"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "151baeee-9bde-4098-bf77-671e0f430418",
      "metadata": {
        "id": "151baeee-9bde-4098-bf77-671e0f430418"
      },
      "outputs": [],
      "source": [
        "train_url = \"http://images.cocodataset.org/zips/train2017.zip\"\n",
        "train_set_zip_filepath = TEMP_DATA_PATH + 'train2017.zip'\n",
        "\n",
        "urllib.request.urlretrieve(train_url, train_set_zip_filepath)\n",
        "\n",
        "with ZipFile(train_set_zip_filepath, 'r') as zObject:\n",
        "    zObject.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download & Unpack Validation Dataset"
      ],
      "metadata": {
        "id": "IlFyPW2uzPYE"
      },
      "id": "IlFyPW2uzPYE"
    },
    {
      "cell_type": "code",
      "source": [
        "val_url = \"http://images.cocodataset.org/zips/val2017.zip\"\n",
        "val_set_zip_filepath = TEMP_DATA_PATH + 'val2017.zip'\n",
        "\n",
        "urllib.request.urlretrieve(val_url, val_set_zip_filepath)\n",
        "\n",
        "with ZipFile(val_set_zip_filepath, 'r') as zObject:\n",
        "    zObject.extractall()"
      ],
      "metadata": {
        "id": "_lT1yz5wzQOb"
      },
      "id": "_lT1yz5wzQOb",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Downloading and Unpacking\n",
        "In this section it's made sure that the files were downloaded and packed correctly by printing the first 5 file names."
      ],
      "metadata": {
        "id": "3fjuXruF0gPT"
      },
      "id": "3fjuXruF0gPT"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "c600f05c-38c1-43ae-8662-052ae60c281a",
      "metadata": {
        "id": "c600f05c-38c1-43ae-8662-052ae60c281a",
        "outputId": "84d1c46e-f170-4b84-c253-7de1873a2424",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files and directories in ' /content/data/train2017 ' :\n",
            "['000000113599.jpg', '000000447074.jpg', '000000103806.jpg', '000000193465.jpg', '000000185697.jpg']\n",
            "Files and directories in ' /content/data/val2017 ' :\n",
            "['000000476704.jpg', '000000201646.jpg', '000000167572.jpg', '000000322944.jpg', '000000574520.jpg']\n"
          ]
        }
      ],
      "source": [
        "# Training Dataset\n",
        "# Get the list of all files and directories\n",
        "train_set_filepath = TEMP_DATA_PATH + 'train2017'\n",
        "train_dir_list     = os.listdir(train_set_filepath)\n",
        "print(\"Files and directories in '\", train_set_filepath, \"' :\")\n",
        "# prints first 5 files\n",
        "print(train_dir_list[0:5])\n",
        "\n",
        "# Validation Dataset\n",
        "# Get the list of all files and directories\n",
        "val_set_filepath = TEMP_DATA_PATH + 'val2017'\n",
        "val_dir_list     = os.listdir(val_set_filepath)\n",
        "print(\"Files and directories in '\", val_set_filepath, \"' :\")\n",
        "# prints first 5 files\n",
        "print(val_dir_list[0:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter Datasets"
      ],
      "metadata": {
        "id": "ZpIqNBkh7hLW"
      },
      "id": "ZpIqNBkh7hLW"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "9d3e4424-6f90-48d0-b1bf-3127890aaa40",
      "metadata": {
        "id": "9d3e4424-6f90-48d0-b1bf-3127890aaa40",
        "outputId": "25bdc026-ecb8-4e63-f457-ccd03cd0a87f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning images in the directory...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118287/118287 [00:04<00:00, 27480.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed: All non-person images have been deleted.\n",
            "Scanning images in the directory...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [00:00<00:00, 33822.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed: All non-person images have been deleted.\n",
            "64115\n",
            "2693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "train_annotations_file = TEMP_DATA_PATH + \"coco_train2017_person.json\"  # JSON file with only person annotations\n",
        "val_annotations_file   = TEMP_DATA_PATH + \"coco_val2017_person.json\"    # JSON file with only person annotations\n",
        "\n",
        "delete_non_person_images(train_annotations_file, train_set_filepath)\n",
        "delete_non_person_images(val_annotations_file, val_set_filepath)\n",
        "\n",
        "print(len(os.listdir(train_set_filepath)))# before: 118287\n",
        "print(len(os.listdir(val_set_filepath)))  # before: 5000"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload Files to Google Drive"
      ],
      "metadata": {
        "id": "6RVgppC673aP"
      },
      "id": "6RVgppC673aP"
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/data/train2017/ /content/drive/MyDrive/eml_challenge/data/COCO/\n",
        "!cp -r /content/data/val2017/ /content/drive/MyDrive/eml_challenge/data/COCO/"
      ],
      "metadata": {
        "id": "19j2g5d78zvs"
      },
      "id": "19j2g5d78zvs",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print /content/data/train2017 disk size\n",
        "\n",
        "!du -sh /content/data/train2017\n",
        "!du -sh /content/data/val2017"
      ],
      "metadata": {
        "id": "UuetfPeJIvop",
        "outputId": "997e6a17-45f9-4563-a6cc-f2bb06810a90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UuetfPeJIvop",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.9G\t/content/data/train2017\n",
            "422M\t/content/data/val2017\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}