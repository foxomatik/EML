{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1mZ_RhF7lqhnHz0hRq_Vc98g-h5hCCFLo",
      "authorship_tag": "ABX9TyN/xFStX0g+yhkNqvKtgyWW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning Tiny Yolo\n",
        "\n",
        "The Tiny Yolo Network is fine tuned to only detect people."
      ],
      "metadata": {
        "id": "qHScsfah94sn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Workspace"
      ],
      "metadata": {
        "id": "ULYvrymCHiBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive Flag"
      ],
      "metadata": {
        "id": "rT5XrmzZIpk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_DRIVE = True"
      ],
      "metadata": {
        "id": "gxgG6hMeI2mn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive"
      ],
      "metadata": {
        "id": "O_yxkMvKHk8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if GOOGLE_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eoGb75c63blH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the directories needed and place uploaded files inside them"
      ],
      "metadata": {
        "id": "MGb2-12sHuSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if GOOGLE_DRIVE:\n",
        "    !pip install torchinfo\n",
        "    !pip install torchvision pillow\n",
        "\n",
        "    !mkdir /content/data\n",
        "\n",
        "    !cp /content/drive/MyDrive/eml_challenge/data/person_indices.json /content/data\n",
        "    !cp -r /content/drive/MyDrive/eml_challenge/utils /content\n",
        "    !cp /content/drive/MyDrive/eml_challenge/tinyyolov2.py /content"
      ],
      "metadata": {
        "id": "oMlA8hKU93Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Append directory paths to system path"
      ],
      "metadata": {
        "id": "SCi-d3NlWeRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if GOOGLE_DRIVE:\n",
        "    import sys\n",
        "    sys.path.append('/content')\n",
        "    sys.path.append('/content/data')\n",
        "    sys.path.append('/content/utils')\n",
        "    sys.path.append('/content/drive/MyDrive/eml_challenge/weights')"
      ],
      "metadata": {
        "id": "75a9jpWp9WfF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Executing Workspace"
      ],
      "metadata": {
        "id": "8ZmM7WjDXXzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing essential libraries"
      ],
      "metadata": {
        "id": "kWzCwEErXfKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchinfo\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import v2\n",
        "import numpy as np\n",
        "import tqdm\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau # Import ReduceLROnPlateau to reduce learning rate of optimizer after Plateau\n",
        "\n",
        "from tinyyolov2 import TinyYoloV2\n",
        "from utils.loss import YoloLoss\n",
        "from utils.dataloaderv2 import VOCDataset\n",
        "from utils.ap import precision_recall_levels, ap, display_roc\n",
        "from utils.yolo import nms, filter_boxes\n",
        "from utils.viz import display_result"
      ],
      "metadata": {
        "id": "idmHICjM9Vq8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define data augmentation pipeline"
      ],
      "metadata": {
        "id": "q6eO4UxRzhSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = v2.Compose([\n",
        "    v2.RandomPhotometricDistort(p=0.5),\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "])"
      ],
      "metadata": {
        "id": "nRFvt-ybzhnd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define data and test loaders"
      ],
      "metadata": {
        "id": "zzzegHdlzFrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = VOCDataset(root=\"/content/data\", year=\"2012\", image_set='train', transform=pipeline, only_person=True) # Contains 2142 pictures\n",
        "test_dataset = VOCDataset(root=\"/content/data\", year=\"2012\", image_set='val', transform=None, only_person=True)        # Contains 2232 pictures\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "T3uAjfo_zF2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Early Stopping class"
      ],
      "metadata": {
        "id": "OqV106CvXmNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, verbose=False, delta=0,\n",
        "                 path='/content/drive/MyDrive/eml_challenge/weights/checkpoint.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last improvement.\n",
        "            verbose (bool): If True, prints a message for each validation metric improvement.\n",
        "            delta (float): Minimum change in the monitored metric to qualify as an improvement.\n",
        "            path (str): Path to save the best model checkpoint.\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.avg_precision_min = 0 # Track the minimum average precision\n",
        "\n",
        "    def __call__(self, avg_precision, model):\n",
        "        score = avg_precision  # Positiv because we maximize AP\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(avg_precision, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(avg_precision, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, avg_precision, model):\n",
        "        \"\"\"Save model when average precision increases.\"\"\"\n",
        "        if self.verbose:\n",
        "            print(f\"Average Precision increased ({self.avg_precision_min:.6f} --> {avg_precision:.6f}). Saving model...\")\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.avg_precision_min = avg_precision\n"
      ],
      "metadata": {
        "id": "wIaSazwOVty3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define fine Tuning function"
      ],
      "metadata": {
        "id": "dkMadXlHXyYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune(net: nn.Module, sd,\n",
        "              data_loader: torch.utils.data.DataLoader, test_loader: torch.utils.data.DataLoader,\n",
        "              num_test_samples: int=0):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      torch_device = torch.device(\"cuda\")\n",
        "      print(\"Using GPU\")\n",
        "    else:\n",
        "      torch_device = torch.device(\"cpu\")\n",
        "      print(\"Using CPU\")\n",
        "\n",
        "    test_AP = []\n",
        "    test_precision = []\n",
        "    test_recall = []\n",
        "\n",
        "    #We load all parameters from the pretrained dict except for the last layer\n",
        "    # net.load_state_dict({k: v for k, v in sd.items() if not '9' in k}, strict=False)\n",
        "    net.load_state_dict({k: v for k, v in sd.items() if not '9' in k}, strict=False)\n",
        "    net.eval()\n",
        "    # Move weights to device\n",
        "    net.to(torch_device)\n",
        "\n",
        "    #We only train the last layer (conv9)\n",
        "    for key, param in net.named_parameters():\n",
        "        if any(x in key for x in ['1', '2', '3', '4', '5', '6', '7']):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # Definition of the loss\n",
        "    criterion = YoloLoss(anchors=net.anchors)\n",
        "    # Definition of the optimizer\n",
        "    learning_rate = 0.001\n",
        "    optimizer = torch.optim.Adam(filter(lambda x: x.requires_grad, net.parameters()), lr=learning_rate)\n",
        "    # Define the ReduceLROnPlateau scheduler\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
        "    # Initialize EarlyStopping\n",
        "    if GOOGLE_DRIVE:\n",
        "        early_stopping = EarlyStopping(patience=7, verbose=True)\n",
        "    else:\n",
        "        early_stopping = EarlyStopping(patience=7, verbose=True, path=\"/checkpoint.pt\")\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        print(f\"Epoch: {epoch}\")\n",
        "        net.train()\n",
        "        if epoch != 0:\n",
        "            for idx, (input, target) in tqdm.tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "                optimizer.zero_grad()\n",
        "                # Move Inputs and targets to Device\n",
        "                input  = input.to(torch_device)\n",
        "                target = target.to(torch_device)\n",
        "                #Yolo head is implemented in the loss for training, therefore yolo=False\n",
        "                output = net(input, yolo=False)\n",
        "                loss, _ = criterion(output, target)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx, (input, target) in tqdm.tqdm(enumerate(test_loader), total=num_test_batches):\n",
        "                net.eval()\n",
        "                input  = input.to(torch_device)\n",
        "                target = target.to(torch_device)\n",
        "                output = net(input, yolo=True)\n",
        "                #The right threshold values can be adjusted for the target application\n",
        "                output = filter_boxes(output, 0.1)\n",
        "                output = nms(output, 0.7)\n",
        "                # Calculate precision and recall for each sample\n",
        "                precision, recall = precision_recall_levels(target[0], output[0])\n",
        "                test_precision.append(precision)\n",
        "                test_recall.append(recall)\n",
        "                if idx == num_test_batches:\n",
        "                    break\n",
        "\n",
        "        #Calculation of average precision with collected samples\n",
        "        average_precision = ap(test_precision, test_recall)\n",
        "        test_AP.append(average_precision)\n",
        "        #plot ROC\n",
        "        display_roc(test_precision, test_recall)\n",
        "        print('average precision', test_AP)\n",
        "        # Adjust learning rate in case of a Plateau of AP\n",
        "        scheduler.step(average_precision)\n",
        "        print(f\"learning rate: {scheduler.get_last_lr()}\")\n",
        "        # Stop training in case there is no further improvement of AP\n",
        "        early_stopping(average_precision, net)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping triggered. Stopping training.\")\n",
        "            torch.cuda.empty_cache()\n",
        "            return net.state_dict()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return net.state_dict()"
      ],
      "metadata": {
        "id": "rBCP5BAT9ijI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Workspace"
      ],
      "metadata": {
        "id": "kgMb3wcNX7WS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We define a tinyyolo network with only two possible classes\n",
        "net = TinyYoloV2(num_classes=1)\n",
        "\n",
        "if GOOGLE_DRIVE:\n",
        "    weights_path = \"/content/drive/MyDrive/eml_challenge/weights/\"\n",
        "else:\n",
        "    weights_path = \"./\"\n",
        "\n",
        "sd = torch.load(weights_path + \"voc_pretrained.pt\", weights_only=True)\n",
        "\n",
        "# Number of Epochs\n",
        "NUM_EPOCHS = 50\n",
        "NUM_TEST_BATCHES = 10\n",
        "\n",
        "sd_fine_tuned = fine_tune(net, sd, data_loader, test_loader, num_test_batches=NUM_TEST_BATCHES)\n",
        "torch.save(sd_fine_tuned, weights_path + \"voc_fine_tuned.pt\")"
      ],
      "metadata": {
        "id": "L2wA0QqK9qZ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}