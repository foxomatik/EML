{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHScsfah94sn"
      },
      "source": [
        "# Fine Tuning Tiny Yolo\n",
        "\n",
        "The Tiny Yolo Network is fine tuned to only detect people."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULYvrymCHiBe"
      },
      "source": [
        "## Prepare Workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT5XrmzZIpk2"
      },
      "source": [
        "### Define GOOGLE COLAB Flag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxgG6hMeI2mn"
      },
      "outputs": [],
      "source": [
        "GOOGLE_COLAB = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_yxkMvKHk8Q"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoGb75c63blH",
        "outputId": "802c4ae2-65f1-41eb-9d21-039db6130350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if GOOGLE_COLAB:\n",
        "    import os\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Check if Google Drive is already mounted\n",
        "    if not os.path.exists('/content/drive/My Drive'):\n",
        "        print(\"Mounting Google Drive...\")\n",
        "        drive.mount('/content/drive')\n",
        "    else:\n",
        "        print(\"Google Drive is already mounted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGb2-12sHuSW"
      },
      "source": [
        "### Set-up Directories & Install Libraires\n",
        "Create the directories needed and copy uploaded files into them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oMlA8hKU93Vi",
        "outputId": "b2a33640-3c11-43e1-8466-8b462096aa20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.5.1->torchvision) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "if GOOGLE_COLAB:\n",
        "    !pip install torchinfo\n",
        "    !pip install torchvision pillow\n",
        "\n",
        "    !mkdir /content/data\n",
        "\n",
        "    !cp /content/drive/MyDrive/eml_challenge/data/person_indices.json /content/data\n",
        "    !cp -r /content/drive/MyDrive/eml_challenge/utils /content\n",
        "    !cp /content/drive/MyDrive/eml_challenge/tinyyolov2.py /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzIVyeeGq_Sg"
      },
      "source": [
        "### Define Path to Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAiKUHurq_aS"
      },
      "outputs": [],
      "source": [
        "if GOOGLE_COLAB:\n",
        "    WEIGHTS_PATH = \"/content/drive/MyDrive/eml_challenge/weights/\"\n",
        "else:\n",
        "    WEIGHTS_PATH = \"./\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCi-d3NlWeRl"
      },
      "source": [
        "### Append Directory Paths to System Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75a9jpWp9WfF"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if GOOGLE_COLAB:\n",
        "    sys.path.append('/content')\n",
        "    sys.path.append('/content/data')\n",
        "    sys.path.append('/content/utils')\n",
        "    sys.path.append(WEIGHTS_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWzCwEErXfKE"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idmHICjM9Vq8"
      },
      "outputs": [],
      "source": [
        "# Pytorch libraries\n",
        "import torch\n",
        "import torchinfo\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Subset\n",
        "from torchvision.transforms import v2\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau # Import ReduceLROnPlateau to reduce learning rate of optimizer after Plateau\n",
        "\n",
        "# Scikit-learn libraires\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Other libraires\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "# EML libraires\n",
        "from tinyyolov2 import TinyYoloV2\n",
        "from utils.loss import YoloLoss\n",
        "from utils.dataloader_v2 import VOCDataset\n",
        "from utils.ap import precision_recall_levels, ap, display_roc\n",
        "from utils.yolo import nms, filter_boxes\n",
        "from utils.viz import display_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZmM7WjDXXzw"
      },
      "source": [
        "## Define Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzzegHdlzFrq"
      },
      "source": [
        "### Define split_dataset_custom Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3uAjfo_zF2L"
      },
      "outputs": [],
      "source": [
        "def split_dataset_custom(dataset: torch.utils.data.Dataset, train_ratio: float, test_ratio: float, validation_ratio: float, pipeline=None):\n",
        "    if (train_ratio + validation_ratio + test_ratio != 1):\n",
        "        raise ValueError(\"The sum of the ratios must be equal to 1.\")\n",
        "\n",
        "    dataset_size = len(dataset)\n",
        "    indices = list(range(dataset_size))\n",
        "\n",
        "    # Step 2: Split into train+validation and test\n",
        "    train_validation_indices, test_indices = train_test_split(indices, test_size=int(test_ratio*dataset_size), random_state=42)\n",
        "    # Step 3: Split train+validation into train and val\n",
        "    train_indices, validation_indices = train_test_split(train_validation_indices, test_size=int(validation_ratio*dataset_size), random_state=42)\n",
        "\n",
        "    # Create Subsets\n",
        "    train_dataset = Subset(dataset, train_indices)\n",
        "    validation_dataset = Subset(dataset, validation_indices)\n",
        "    test_dataset = Subset(dataset, test_indices)\n",
        "\n",
        "    if pipeline:\n",
        "        train_dataset.transform = pipeline\n",
        "\n",
        "    return train_dataset, validation_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define split_dataset_kfolds Function"
      ],
      "metadata": {
        "id": "HLC0jmCItiQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset_kfolds(dataset: torch.utils.data.Dataset, train_indices, validation_indices, pipeline):\n",
        "    train_dataset = Subset(dataset, train_indices)\n",
        "    validation_dataset = Subset(dataset, validation_indices)\n",
        "\n",
        "    if pipeline:\n",
        "        train_dataset.transform = pipeline\n",
        "\n",
        "    return train_dataset, validation_dataset"
      ],
      "metadata": {
        "id": "bceoG59-tieU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqV106CvXmNV"
      },
      "source": [
        "### Define Early Stopping Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIaSazwOVty3"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0,\n",
        "                 path='/content/drive/MyDrive/eml_challenge/weights/checkpoint.pt',\n",
        "                 best_model_path='/content/drive/MyDrive/eml_challenge/weights/voc_fine_tuned.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last improvement.\n",
        "            verbose (bool): If True, prints a message for each validation metric improvement.\n",
        "            delta (float): Minimum change in the monitored metric to qualify as an improvement.\n",
        "            path (str): Path to save the best model checkpoint.\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.best_model_path = best_model_path\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.avg_precision_min = 0 # Track the minimum average precision\n",
        "\n",
        "    def __call__(self, avg_precision, model):\n",
        "        score = avg_precision  # Positive because we maximize AP\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(avg_precision, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "                torch.save(model.state_dict(), self.best_model_path)\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(avg_precision, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, avg_precision, model):\n",
        "        \"\"\"Save model when average precision increases.\"\"\"\n",
        "        if self.verbose:\n",
        "            print(f\"Average Precision increased ({self.avg_precision_min:.6f} --> {avg_precision:.6f}). Saving model...\")\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.avg_precision_min = avg_precision\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP9hv7w7XKv6"
      },
      "source": [
        "### Define train, validate and test Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wrk4ghxXK6-"
      },
      "outputs": [],
      "source": [
        "def train(net: nn.Module, data_loader: torch.utils.data.DataLoader, optimizer, criterion, device):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "    This function trains the network for one epoch and returns average loss.\n",
        "\n",
        "    Args:\n",
        "    net: the network to train\n",
        "    data_loader: the data loader for the training set\n",
        "    optimizer: the optimizer to use for training\n",
        "    criterion: the loss function to use for training\n",
        "    device: the device to use for training\n",
        "    \"\"\"\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    net.train()\n",
        "    # Move weights to device\n",
        "    net.to(device)\n",
        "\n",
        "    for idx, (input, target) in tqdm.tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "        # Move Inputs and targets to Device\n",
        "        input  = input.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        #Yolo head is implemented in the loss for training, therefore yolo=False\n",
        "        output = net(input, yolo=False)\n",
        "        loss, _ = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(data_loader)\n",
        "\n",
        "    return average_loss\n",
        "\n",
        "def validate(net: nn.Module, data_loader: torch.utils.data.DataLoader, device):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "    This function is used to validate the network. It is currently needed for\n",
        "    early stopping and learning rate adjustment.\n",
        "\n",
        "    Args:\n",
        "    net: the network to test\n",
        "    data_loader: the data loader for the test set\n",
        "    device: the device to use for training\n",
        "    \"\"\"\n",
        "\n",
        "    eval_precision = []\n",
        "    eval_recall = []\n",
        "\n",
        "    net.eval()\n",
        "    # Move weights to device\n",
        "    net.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (input, target) in tqdm.tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "            input  = input.to(device)\n",
        "            target = target.to(device)\n",
        "            output = net(input, yolo=True)\n",
        "            #The right threshold values can be adjusted for the target application\n",
        "            output = filter_boxes(output, CONFIDENCE_THRESHOLD)\n",
        "            output = nms(output, NMS_THRESHOLD)\n",
        "            if idx == 0:\n",
        "                input  = input.to(torch.device('cpu'))\n",
        "                target = target.to(torch.device('cpu'))\n",
        "                input  = input.to(device)\n",
        "                target = target.to(device)\n",
        "            # Calculate precision and recall for each sample\n",
        "            for i in range(len(target)):\n",
        "                precision, recall = precision_recall_levels(target[i], output[i])\n",
        "                eval_precision.append(precision)\n",
        "                eval_recall.append(recall)\n",
        "\n",
        "    # Calculate average precision with collected samples\n",
        "    average_precision = ap(eval_precision, eval_recall)\n",
        "    # Plot ROC\n",
        "    display_roc(eval_precision, eval_recall)\n",
        "\n",
        "    return average_precision\n",
        "\n",
        "\n",
        "def test(net: nn.Module, data_loader: torch.utils.data.DataLoader, device, best_model_path):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "    This function tests the network.\n",
        "\n",
        "    Args:\n",
        "    net: the network to test\n",
        "    data_loader: the data loader for the test set\n",
        "    device: the device to use for training\n",
        "    num_validation_samples: the number of passed images to the validate function\n",
        "    \"\"\"\n",
        "\n",
        "    test_precision = []\n",
        "    test_recall = []\n",
        "\n",
        "    # Load weights and move them to device\n",
        "    sd = torch.load(best_model_path, weights_only=True)\n",
        "    net.load_state_dict(sd)\n",
        "    net.to(device)\n",
        "    net.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (input, target) in tqdm.tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "            input  = input.to(device)\n",
        "            target = target.to(device)\n",
        "            output = net(input, yolo=True)\n",
        "            #The right threshold values can be adjusted for the target application\n",
        "            output = filter_boxes(output, CONFIDENCE_THRESHOLD)\n",
        "            output = nms(output, NMS_THRESHOLD)\n",
        "            # Calculate precision and recall for each sample\n",
        "            for i in range(len(target)):\n",
        "                precision, recall = precision_recall_levels(target[i], output[i])\n",
        "                test_precision.append(precision)\n",
        "                test_recall.append(recall)\n",
        "\n",
        "    # Calculate average precision with collected samples\n",
        "    average_precision = ap(test_precision, test_recall)\n",
        "    # Plot ROC\n",
        "    display_roc(test_precision, test_recall)\n",
        "\n",
        "    return average_precision\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sVXLO9yqzQM"
      },
      "source": [
        "### Define plot_loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrnmZpZMqzZL"
      },
      "outputs": [],
      "source": [
        "def plot_loss(losses):\n",
        "    \"\"\"\n",
        "    Plots the losses over epochs.\n",
        "\n",
        "    Args:\n",
        "        losses (list of float): List of loss values, one for each epoch.\n",
        "    \"\"\"\n",
        "    epochs = range(1, len(losses) + 1)  # Epoch numbers start at 1\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, losses, marker='o', label='Loss')\n",
        "    plt.title(\"Loss over Epochs\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkMadXlHXyYT"
      },
      "source": [
        "### Define fine_tune Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBCP5BAT9ijI"
      },
      "outputs": [],
      "source": [
        "def fine_tune(net: nn.Module,\n",
        "              sd,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              validation_loader: torch.utils.data.DataLoader,\n",
        "              test_loader: torch.utils.data.DataLoader):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      torch_device = torch.device(\"cuda\")\n",
        "      print(\"Using GPU\")\n",
        "    else:\n",
        "      torch_device = torch.device(\"cpu\")\n",
        "      print(\"Using CPU\")\n",
        "\n",
        "    eval_AP = []\n",
        "    epoch_loss_list = []\n",
        "\n",
        "    #We load all parameters from the pretrained dict except for the last layer\n",
        "    net.load_state_dict({k: v for k, v in sd.items() if not '9' in k}, strict=False)\n",
        "\n",
        "    #We only train the last layer (conv9)\n",
        "    for key, param in net.named_parameters():\n",
        "        if any(x in key for x in ['1', '2', '3', '4', '5', '6', '7']):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # Definition of the loss\n",
        "    criterion = YoloLoss(anchors=net.anchors)\n",
        "\n",
        "    # Definition of the optimizer\n",
        "    learning_rate = 0.001\n",
        "    optimizer = torch.optim.Adam(filter(lambda x: x.requires_grad, net.parameters()), lr=learning_rate)\n",
        "\n",
        "    # Define the ReduceLROnPlateau scheduler\n",
        "    if ADJUST_LEARNING_RATE:\n",
        "        scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
        "\n",
        "    # Initialize EarlyStopping\n",
        "    if EARLY_STOPPING:\n",
        "        early_stopping = EarlyStopping(patience=5, verbose=True, path=WEIGHTS_PATH+\"checkpoint.pt\", best_model_path=WEIGHTS_PATH+\"voc_fine_tuned.pt\")\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        print(\"****************************************************************************************************************************\")\n",
        "        print(f\"Epoch: {epoch+1}/{NUM_EPOCHS}\")\n",
        "\n",
        "        # Train the network\n",
        "        average_loss = train(net, data_loader, optimizer, criterion, torch_device)\n",
        "        epoch_loss_list.append(average_loss)\n",
        "\n",
        "        # Validate the network\n",
        "        average_precision = validate(net, validation_loader, torch_device)\n",
        "        eval_AP.append(average_precision)\n",
        "        print(f'Average Precision in the last 5 Epochs: {eval_AP[-5:]}')\n",
        "        print(f'Average Precision This Epoch: {average_precision:.3%}')\n",
        "        # Adjust learning rate in case of a Plateau of AP\n",
        "        if ADJUST_LEARNING_RATE:\n",
        "            scheduler.step(average_precision)\n",
        "            print(f\"Learning Rate: {scheduler.get_last_lr()}\")\n",
        "        # Stop training in case there is no further improvement of AP\n",
        "        if EARLY_STOPPING:\n",
        "            early_stopping(average_precision, net)\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping triggered. Stopping training.\")\n",
        "                break\n",
        "\n",
        "    if EARLY_STOPPING:\n",
        "        if not early_stopping.early_stop:\n",
        "            torch.save(net.state_dict(), WEIGHTS_PATH + \"voc_fine_tuned.pt\")\n",
        "            print(\"No early stopping triggered. Training completed.\")\n",
        "\n",
        "    best_validation_average_precision = max(eval_AP)\n",
        "    # Test the network\n",
        "    test_average_precision = test(net, test_loader, torch_device, best_model_path=WEIGHTS_PATH+\"voc_fine_tuned.pt\")\n",
        "    print(f'Best Validation Average Precision: {best_validation_average_precision:.3%}')\n",
        "    print(f'Test Average Precision:            {test_average_precision:.3%}')\n",
        "    print(\"****************************************************************************************************************************\")\n",
        "\n",
        "    # Plot the loss curve\n",
        "    plot_loss(epoch_loss_list)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return best_validation_average_precision, test_average_precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgMb3wcNX7WS"
      },
      "source": [
        "## Execute Workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6eO4UxRzhSG"
      },
      "source": [
        "### Define data augmentation pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRFvt-ybzhnd"
      },
      "outputs": [],
      "source": [
        "pipeline = v2.Compose([\n",
        "    v2.RandomPhotometricDistort(p=0.5),\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6A1qhgFlikJ"
      },
      "source": [
        "### Define Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acFb6EnJlmJ7"
      },
      "outputs": [],
      "source": [
        "# Number or Epochs for fine-tuning\n",
        "NUM_EPOCHS               = 30\n",
        "# Thresholds\n",
        "CONFIDENCE_THRESHOLD     = 0.0\n",
        "NMS_THRESHOLD            = 0.5\n",
        "# Batch sizes\n",
        "TRAIN_BATCH_SIZE         = 128\n",
        "VALIDATION_BATCH_SIZE    = 128\n",
        "TEST_BATCH_SIZE          = 128\n",
        "# Flags\n",
        "ADJUST_LEARNING_RATE     = False\n",
        "EARLY_STOPPING           = True\n",
        "K_FOLDS                  = True\n",
        "CUSTOM_SPLIT             = False\n",
        "# Dataset custom split ratios\n",
        "if CUSTOM_SPLIT:\n",
        "    TRAIN_DATASET_RATIO      = 0.70\n",
        "    TEST_DATASET_RATIO       = 0.20\n",
        "    VALIDATION_DATASET_RATIO = 0.10\n",
        "# K-Folds\n",
        "if K_FOLDS:\n",
        "    NUMBER_OF_FOLDS          = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYg9JHS8l_bB"
      },
      "source": [
        "### Define Datasets and Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXsvk6hml-vU"
      },
      "outputs": [],
      "source": [
        "if CUSTOM_SPLIT:\n",
        "    dataset = VOCDataset(root=\"/content/data\", year=\"2012\", image_set='trainval', transform=None, only_person=True) # Contains 4374 pictures\n",
        "\n",
        "    train_dataset, validation_dataset, test_dataset = split_dataset_custom(dataset,\n",
        "                                                                           train_ratio=TRAIN_DATASET_RATIO,\n",
        "                                                                           test_ratio=TEST_DATASET_RATIO,\n",
        "                                                                           validation_ratio=VALIDATION_DATASET_RATIO,\n",
        "                                                                           pipeline=pipeline)\n",
        "\n",
        "    train_loader      = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
        "    validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=VALIDATION_BATCH_SIZE, shuffle=True)\n",
        "    test_loader       = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=True)\n",
        "\n",
        "if K_FOLDS:\n",
        "    train_dataset = VOCDataset(root=\"/content/data\", year=\"2012\", image_set='train', transform=pipeline, only_person=True) # Contains 2142 pictures\n",
        "    test_dataset  = VOCDataset(root=\"/content/data\", year=\"2012\", image_set='val', only_person=True)   # Contains 2232 pictures\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy4iXRpr1ZF9"
      },
      "source": [
        "### Improvement Ideas\n",
        "\n",
        "\n",
        "1. try different splits\n",
        "2. try different crop methods for data augmentation\n",
        "3. print loss and plot the loss curve accross no. of epochs\n",
        "4. use display_result function to evaluate confidence and NMS thesholds\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a4e549euvT5"
      },
      "source": [
        "### Fine-tune the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2wA0QqK9qZ-"
      },
      "outputs": [],
      "source": [
        "# We define a tinyyolo network with only two possible classes\n",
        "net = TinyYoloV2(num_classes=1)\n",
        "\n",
        "sd = torch.load(WEIGHTS_PATH + \"voc_pretrained.pt\", weights_only=True)\n",
        "\n",
        "if K_FOLDS:\n",
        "    kf = KFold(n_splits=NUMBER_OF_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "    fold_validation_average_precisions = []\n",
        "    fold_test_average_precisions       = []\n",
        "\n",
        "    for fold, (test_indices, validation_indices) in enumerate(kf.split(train_dataset)):\n",
        "        print(f\"Fold {fold + 1}/{NUMBER_OF_FOLDS}\")\n",
        "\n",
        "        # Create subsets for training and validation\n",
        "        test_subset, validation_subset = split_dataset_kfolds(dataset=test_dataset,\n",
        "                                                               train_indices=test_indices,\n",
        "                                                               validation_indices=validation_indices,\n",
        "                                                               pipeline=None)\n",
        "\n",
        "        test_loader       = torch.utils.data.DataLoader(dataset=test_subset, batch_size=TEST_BATCH_SIZE, shuffle=True)\n",
        "        validation_loader = torch.utils.data.DataLoader(dataset=validation_subset, batch_size=VALIDATION_BATCH_SIZE, shuffle=True)\n",
        "\n",
        "        # Fine-tune the network\n",
        "        fold_validation_average_precision, fold_test_average_precision = fine_tune(net, sd, train_loader, validation_loader, test_loader)\n",
        "\n",
        "        fold_validation_average_precisions.append(fold_validation_average_precision)\n",
        "        fold_test_average_precisions.append(fold_test_average_precision)\n",
        "\n",
        "    # Calculate the mean average precision across folds\n",
        "    mean_average_precision = sum(fold_test_average_precisions) / NUMBER_OF_FOLDS\n",
        "\n",
        "    print(f\"Validation Average Precisions across {NUMBER_OF_FOLDS} folds: {fold_validation_average_precisions}\")\n",
        "    print(f\"Test Average Precisions across {NUMBER_OF_FOLDS} folds: {fold_test_average_precisions}\")\n",
        "    print(f\"Mean Average Precision across {NUMBER_OF_FOLDS} folds: {mean_average_precision}\")\n",
        "else:\n",
        "    # Fine-tune the network\n",
        "    fine_tune(net, sd, train_loader, validation_loader, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Disconnect runtime"
      ],
      "metadata": {
        "id": "BOQB5eyuCqmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if GOOGLE_COLAB:\n",
        "    from google.colab import runtime\n",
        "    runtime.unassign()"
      ],
      "metadata": {
        "id": "EZrHhO7GCqvS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}