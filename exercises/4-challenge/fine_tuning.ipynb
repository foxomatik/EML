{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHScsfah94sn"
      },
      "source": [
        "# Fine Tuning Tiny Yolo\n",
        "\n",
        "The Tiny Yolo Network is fine tuned to only detect people."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULYvrymCHiBe"
      },
      "source": [
        "## Prepare Workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT5XrmzZIpk2"
      },
      "source": [
        "### Google Drive Flag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gxgG6hMeI2mn"
      },
      "outputs": [],
      "source": [
        "GOOGLE_DRIVE = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_yxkMvKHk8Q"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoGb75c63blH"
      },
      "outputs": [],
      "source": [
        "if GOOGLE_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGb2-12sHuSW"
      },
      "source": [
        "### Create the directories needed and place uploaded files inside them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMlA8hKU93Vi"
      },
      "outputs": [],
      "source": [
        "if GOOGLE_DRIVE:\n",
        "    !pip install torchinfo\n",
        "    !pip install torchvision pillow\n",
        "\n",
        "    !mkdir /content/data\n",
        "\n",
        "    !cp /content/drive/MyDrive/eml_challenge/data/person_indices.json /content/data\n",
        "    !cp -r /content/drive/MyDrive/eml_challenge/utils /content\n",
        "    !cp /content/drive/MyDrive/eml_challenge/tinyyolov2.py /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCi-d3NlWeRl"
      },
      "source": [
        "### Append directory paths to system path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "75a9jpWp9WfF"
      },
      "outputs": [],
      "source": [
        "if GOOGLE_DRIVE:\n",
        "    import sys\n",
        "    sys.path.append('/content')\n",
        "    sys.path.append('/content/data')\n",
        "    sys.path.append('/content/utils')\n",
        "    sys.path.append('/content/drive/MyDrive/eml_challenge/weights')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZmM7WjDXXzw"
      },
      "source": [
        "## Executing Workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWzCwEErXfKE"
      },
      "source": [
        "### Importing essential libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "idmHICjM9Vq8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchinfo\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import v2\n",
        "import numpy as np\n",
        "import tqdm\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau # Import ReduceLROnPlateau to reduce learning rate of optimizer after Plateau\n",
        "\n",
        "from tinyyolov2 import TinyYoloV2\n",
        "from utils.loss import YoloLoss\n",
        "from utils.dataloader_v2 import VOCDataset\n",
        "from utils.ap import precision_recall_levels, ap, display_roc\n",
        "from utils.yolo import nms, filter_boxes\n",
        "from utils.viz import display_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6eO4UxRzhSG"
      },
      "source": [
        "### Define data augmentation pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nRFvt-ybzhnd"
      },
      "outputs": [],
      "source": [
        "pipeline = v2.Compose([\n",
        "    v2.RandomPhotometricDistort(p=0.5),\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzzegHdlzFrq"
      },
      "source": [
        "### Define data and test loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3uAjfo_zF2L"
      },
      "outputs": [],
      "source": [
        "train_dataset = VOCDataset(root=\"/content/data\", year=\"2012\", image_set='train', transform=pipeline, only_person=True) # Contains 2142 pictures\n",
        "test_dataset = VOCDataset(root=\"/content/data\", year=\"2012\", image_set='val', transform=None, only_person=True)        # Contains 2232 pictures\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqV106CvXmNV"
      },
      "source": [
        "### Define Early Stopping class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wIaSazwOVty3"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, verbose=False, delta=0,\n",
        "                 path='/content/drive/MyDrive/eml_challenge/weights/checkpoint.pt',\n",
        "                 best_model_path='/content/drive/MyDrive/eml_challenge/weights/voc_fine_tuned.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last improvement.\n",
        "            verbose (bool): If True, prints a message for each validation metric improvement.\n",
        "            delta (float): Minimum change in the monitored metric to qualify as an improvement.\n",
        "            path (str): Path to save the best model checkpoint.\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.best_model_path = best_model_path\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.avg_precision_min = 0 # Track the minimum average precision\n",
        "\n",
        "    def __call__(self, avg_precision, model):\n",
        "        score = avg_precision  # Positiv because we maximize AP\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(avg_precision, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "                torch.save(model.state_dict(), self.best_model_path)\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(avg_precision, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, avg_precision, model):\n",
        "        \"\"\"Save model when average precision increases.\"\"\"\n",
        "        if self.verbose:\n",
        "            print(f\"Average Precision increased ({self.avg_precision_min:.6f} --> {avg_precision:.6f}). Saving model...\")\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.avg_precision_min = avg_precision\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP9hv7w7XKv6"
      },
      "source": [
        "### Define train, validate and test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5wrk4ghxXK6-"
      },
      "outputs": [],
      "source": [
        "def train(net: nn.Module, data_loader: torch.utils.data.DataLoader, optimizer, criterion, device):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "    This function trains the network for one epoch.\n",
        "\n",
        "    Args:\n",
        "    net: the network to train\n",
        "    data_loader: the data loader for the training set\n",
        "    optimizer: the optimizer to use for training\n",
        "    criterion: the loss function to use for training\n",
        "    device: the device to use for training\n",
        "    \"\"\"\n",
        "\n",
        "    net.train()\n",
        "    # Move weights to device\n",
        "    net.to(device)\n",
        "\n",
        "    for idx, (input, target) in tqdm.tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "        # Move Inputs and targets to Device\n",
        "        input  = input.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        #Yolo head is implemented in the loss for training, therefore yolo=False\n",
        "        output = net(input, yolo=False)\n",
        "        loss, _ = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def validate(net: nn.Module, data_loader: torch.utils.data.DataLoader, device, num_validation_samples):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "    This function uses the first \"num_validation_samples\" images from the test data set to validate the network.\n",
        "    Keep in mind that this function only works for batch_size=1 and shuffle=False.\n",
        "\n",
        "    Args:\n",
        "    net: the network to test\n",
        "    data_loader: the data loader for the test set\n",
        "    device: the device to use for training\n",
        "    num_validation_samples: the number of samples to use for validation\n",
        "    \"\"\"\n",
        "\n",
        "    eval_precision = []\n",
        "    eval_recall = []\n",
        "\n",
        "    net.eval()\n",
        "    # Move weights to device\n",
        "    net.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (input, target) in tqdm.tqdm(enumerate(test_loader), total=num_validation_samples):\n",
        "            input  = input.to(device)\n",
        "            target = target.to(device)\n",
        "            output = net(input, yolo=True)\n",
        "            #The right threshold values can be adjusted for the target application\n",
        "            output = filter_boxes(output, CONFIDENCE_THRESHOLD)\n",
        "            output = nms(output, NMS_THRESHOLD)\n",
        "            # Calculate precision and recall for each sample\n",
        "            precision, recall = precision_recall_levels(target[0], output[0])\n",
        "            eval_precision.append(precision)\n",
        "            eval_recall.append(recall)\n",
        "            if idx == num_validation_samples:\n",
        "                break\n",
        "\n",
        "    # Calculate average precision with collected samples\n",
        "    average_precision = ap(eval_precision, eval_recall)\n",
        "    # Plot ROC\n",
        "    display_roc(eval_precision, eval_recall)\n",
        "\n",
        "    return average_precision\n",
        "\n",
        "\n",
        "def test(net: nn.Module, data_loader: torch.utils.data.DataLoader, device, num_validation_samples, best_model_path):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "    This function skips the images passed during the validation and uses the rest of the\n",
        "    images from the test data set to test the network. This is done to reduce overfitting\n",
        "    and improve generalization. Keep in mind that this function only works for batch_size=1\n",
        "    and shuffle=False.\n",
        "\n",
        "    Args:\n",
        "    net: the network to test\n",
        "    data_loader: the data loader for the test set\n",
        "    device: the device to use for training\n",
        "    num_validation_samples: the number of passed images to the validate function\n",
        "    \"\"\"\n",
        "\n",
        "    test_precision = []\n",
        "    test_recall = []\n",
        "\n",
        "    # Load weights and move them to device\n",
        "    sd = torch.load(best_model_path, weights_only=True)\n",
        "    net.load_state_dict(sd)\n",
        "    net.to(device)\n",
        "    net.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (input, target) in tqdm.tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "            if idx >= num_validation_samples:\n",
        "                input  = input.to(device)\n",
        "                target = target.to(device)\n",
        "                output = net(input, yolo=True)\n",
        "                #The right threshold values can be adjusted for the target application\n",
        "                output = filter_boxes(output, CONFIDENCE_THRESHOLD)\n",
        "                output = nms(output, NMS_THRESHOLD)\n",
        "                # Calculate precision and recall for each sample\n",
        "                precision, recall = precision_recall_levels(target[0], output[0])\n",
        "                test_precision.append(precision)\n",
        "                test_recall.append(recall)\n",
        "\n",
        "    # Calculate average precision with collected samples\n",
        "    average_precision = ap(test_precision, test_recall)\n",
        "    # Plot ROC\n",
        "    display_roc(test_precision, test_recall)\n",
        "\n",
        "    return average_precision\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkMadXlHXyYT"
      },
      "source": [
        "### Define fine Tuning function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rBCP5BAT9ijI"
      },
      "outputs": [],
      "source": [
        "def fine_tune(net: nn.Module, sd,\n",
        "              data_loader: torch.utils.data.DataLoader, test_loader: torch.utils.data.DataLoader,\n",
        "              num_eval_samples: int=0):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      torch_device = torch.device(\"cuda\")\n",
        "      print(\"Using GPU\")\n",
        "    else:\n",
        "      torch_device = torch.device(\"cpu\")\n",
        "      print(\"Using CPU\")\n",
        "\n",
        "    eval_AP = []\n",
        "\n",
        "    #We load all parameters from the pretrained dict except for the last layer\n",
        "    net.load_state_dict({k: v for k, v in sd.items() if not '9' in k}, strict=False)\n",
        "\n",
        "    #We only train the last layer (conv9)\n",
        "    for key, param in net.named_parameters():\n",
        "        if any(x in key for x in ['1', '2', '3', '4', '5', '6', '7']):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # Definition of the loss\n",
        "    criterion = YoloLoss(anchors=net.anchors)\n",
        "\n",
        "    # Definition of the optimizer\n",
        "    learning_rate = 0.001\n",
        "    optimizer = torch.optim.Adam(filter(lambda x: x.requires_grad, net.parameters()), lr=learning_rate)\n",
        "\n",
        "    # Define the ReduceLROnPlateau scheduler\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
        "\n",
        "    # Initialize EarlyStopping\n",
        "    early_stopping = EarlyStopping(patience=7, verbose=True, path=WEIGHTS_PATH+\"checkpoint.pt\", best_model_path=WEIGHTS_PATH+\"voc_fine_tuned.pt\")\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        print(f\"Epoch: {epoch}\")\n",
        "\n",
        "        # Train the network\n",
        "        if epoch != 0:\n",
        "            train(net, data_loader, optimizer, criterion, torch_device)\n",
        "\n",
        "        # Validate the network\n",
        "        average_precision = validate(net, test_loader, torch_device, num_eval_samples=num_eval_samples)\n",
        "        eval_AP.append(average_precision)\n",
        "        print('average precision', eval_AP)\n",
        "        # Adjust learning rate in case of a Plateau of AP\n",
        "        scheduler.step(average_precision)\n",
        "        print(f\"learning rate: {scheduler.get_last_lr()}\")\n",
        "        # Stop training in case there is no further improvement of AP\n",
        "        early_stopping(average_precision, net)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping triggered. Stopping training.\")\n",
        "            break\n",
        "\n",
        "    if not early_stopping.early_stop:\n",
        "        torch.save(net.state_dict(), WEIGHTS_PATH + \"voc_fine_tuned.pt\")\n",
        "        print(\"No early stopping triggered. Training completed.\")\n",
        "\n",
        "    # Test the network\n",
        "    final_average_precision = test(net, test_loader, torch_device, num_eval_samples=num_eval_samples, best_model_path=WEIGHTS_PATH+\"voc_fine_tuned.pt\")\n",
        "    print('final average precision: ', final_average_precision)\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgMb3wcNX7WS"
      },
      "source": [
        "## Testing Workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2wA0QqK9qZ-"
      },
      "outputs": [],
      "source": [
        "# We define a tinyyolo network with only two possible classes\n",
        "net = TinyYoloV2(num_classes=1)\n",
        "\n",
        "if GOOGLE_DRIVE:\n",
        "    WEIGHTS_PATH = \"/content/drive/MyDrive/eml_challenge/weights/\"\n",
        "else:\n",
        "    WEIGHTS_PATH = \"./\"\n",
        "\n",
        "sd = torch.load(WEIGHTS_PATH + \"voc_pretrained.pt\", weights_only=True)\n",
        "\n",
        "# Number of Epochs\n",
        "NUM_EPOCHS = 50\n",
        "NUM_VALIDATION_SAMPLES = 350\n",
        "# Thresholds\n",
        "CONFIDENCE_THRESHOLD = 0.0\n",
        "NMS_THRESHOLD = 0.5\n",
        "\n",
        "# Fine-tune the network\n",
        "fine_tune(net, sd, data_loader, test_loader, num_eval_samples=NUM_VALIDATION_SAMPLES)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
