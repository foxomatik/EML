{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "banner-elizabeth",
   "metadata": {},
   "source": [
    "# Embedded ML Lab - Excercise 3 - Pruning\n",
    "\n",
    "In this exercise, we will explore pruning of NNs. The pruning experiments are split in two parts. Firstly, we will explore pruning for compressing the model size. For that, we will drop parameters of the network in an unstructured way. Secondly, we will explore Pruning to speed up NN inference. For that we will use \"structured pruning\" and conv-layer output channels.\n",
    "\n",
    "For this lab, we use a little bit heavier version of the previously used `CifarNet`. The implementation can be found in the `net.py` file. Additionally, there are a couple of utility functions in `utils.py`. For the first part of the lab, we will use `net_acc` to measure the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "printable-government",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/cifar-10-python.tar.gz\n",
      "Extracting data/cifar-10-python.tar.gz to data/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.rand(1).to('cuda') #initialize cuda context (might take a while)\n",
    "\n",
    "from net import CifarNet\n",
    "import torch\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "tf = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "testloader = torch.utils.data.DataLoader(torchvision.datasets.CIFAR10('data/', train=False, download=True, transform=tf), shuffle=False, batch_size=32)\n",
    "trainloader = torch.utils.data.DataLoader(torchvision.datasets.CIFAR10('data/', train=True, download=True, transform=tf), shuffle=False, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "registered-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CifarNet Accuracy: 85.3%\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "net = CifarNet()\n",
    "state_dict = torch.load('state_dict__cifarnet.pt')\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "from utils import net_acc, size_on_disk\n",
    "\n",
    "print(f\"CifarNet Accuracy: {net_acc(CifarNet, state_dict, testloader, batches=128, device='cuda')}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-bracket",
   "metadata": {},
   "source": [
    "We now explore pruning methods to compress the model size, by setting parameters to zero. We evaluate two methods: Random pruning, and l1-norm pruning.\n",
    "\n",
    "Your Tasks:\n",
    "* Implement the function `random_unstructured_pruning`. This function takes a state_dict as input and returns a state_dict with same elements and dimensions as output. Prune (set to zero) a ratio of `prune_ratio` per convolutional layer (filter). The bias can be left untouched, as well as the FC layer.\n",
    "    * One way to do this to use as mask (e.g., a random torch tensor) where you randomly clip `prune_ratio`to zero and the remainder to one, that you multiply with the convolutional layer's filters.\n",
    "    \n",
    "* Implement the function `l1_unstructured_pruning`. Here, instead of randomly pruning parameters to zero, you are supposed to set the parameters that have the lowest magnitude to zero.\n",
    "    * One way to do something like this is with numpy `percentile` (i.e., check https://numpy.org/doc/stable/reference/generated/numpy.percentile.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "44376375-ab82-4503-9052-bca90248e567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "conv2.weight\n",
      "conv2.bias\n",
      "conv3.weight\n",
      "conv3.bias\n",
      "conv4.weight\n",
      "conv4.bias\n",
      "conv5.weight\n",
      "conv5.bias\n",
      "conv6.weight\n",
      "conv6.bias\n",
      "fc.weight\n",
      "fc.bias\n",
      "0\n",
      "torch.Size([16, 3, 3, 3])\n",
      "1\n",
      "torch.Size([32, 16, 3, 3])\n",
      "2\n",
      "torch.Size([64, 32, 3, 3])\n",
      "3\n",
      "torch.Size([128, 64, 3, 3])\n",
      "4\n",
      "torch.Size([256, 128, 3, 3])\n",
      "5\n",
      "torch.Size([256, 256, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Test of random pruning\n",
    "state_dict = torch.load('state_dict__cifarnet.pt')\n",
    "for key in state_dict:\n",
    "    print(key)\n",
    "\n",
    "for num in range(6):\n",
    "    # print(f'\\nnum: {num}')\n",
    "    conv_layer = state_dict.get('conv{}.weight'.format(num+1))\n",
    "    conv_layer = conv_layer.to('cuda')\n",
    "\n",
    "    conv_mask = torch.rand(conv_layer.shape)\n",
    "    conv_mask = torch.where(conv_mask<0.1, 0.0, 1.0)\n",
    "    conv_mask = conv_mask.to('cuda')\n",
    "    #print(conv_mask)\n",
    "\n",
    "    # print(\"BEFORE:\\t#####################################\")\n",
    "    #print(state_dict.get('conv{}.weight'.format(num+1)))\n",
    "    state_dict['conv{}.weight'.format(num+1)] = conv_layer*conv_mask\n",
    "    # print(\"AFTER:\\t#####################################\")\n",
    "    #print(state_dict.get('conv{}.weight'.format(num+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f7dc8c6-8d09-4c82-b4fc-21e6dea8708d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "conv1.weight\n",
      "conv1.bias\n",
      "conv2.weight\n",
      "conv2.bias\n",
      "conv3.weight\n",
      "conv3.bias\n",
      "conv4.weight\n",
      "conv4.bias\n",
      "conv5.weight\n",
      "conv5.bias\n",
      "conv6.weight\n",
      "conv6.bias\n",
      "fc.weight\n",
      "fc.bias\n",
      "torch.Size([16, 3, 3, 3])\n",
      "tensor([[[[7.2481e-03, 1.0064e-02, 8.7275e-03],\n",
      "          [2.4037e-03, 1.9652e-02, 1.0658e-02],\n",
      "          [1.8738e-02, 1.6389e-02, 1.6932e-02]],\n",
      "\n",
      "         [[1.1843e-02, 1.7843e-02, 2.2775e-02],\n",
      "          [4.8765e-03, 1.2428e-03, 1.2195e-02],\n",
      "          [3.9174e-02, 1.0942e-03, 4.7779e-02]],\n",
      "\n",
      "         [[8.1634e-02, 8.3447e-02, 7.1352e-02],\n",
      "          [7.7457e-02, 9.0063e-02, 8.5804e-02],\n",
      "          [4.7858e-02, 8.7284e-02, 8.3801e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.9410e-01, 1.1500e+00, 4.0468e-01],\n",
      "          [3.1723e-01, 6.7431e-01, 1.8661e+00],\n",
      "          [5.2850e-01, 2.5928e-01, 2.1434e-01]],\n",
      "\n",
      "         [[8.4645e-02, 7.0038e-01, 2.8129e-01],\n",
      "          [5.6546e-01, 3.3168e-01, 2.3587e+00],\n",
      "          [1.9476e-01, 2.7141e-01, 2.9519e-01]],\n",
      "\n",
      "         [[1.4705e-01, 4.1965e-01, 3.5671e-01],\n",
      "          [1.0378e+00, 5.7006e-01, 2.0748e+00],\n",
      "          [3.0202e-01, 2.8270e-01, 2.3094e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.7436e-01, 2.2794e-01, 2.1641e-01],\n",
      "          [3.2159e-03, 6.5579e-01, 2.0728e-01],\n",
      "          [1.7029e-01, 1.2137e-01, 4.4231e-01]],\n",
      "\n",
      "         [[3.6360e-01, 1.1564e-01, 4.0637e-02],\n",
      "          [7.7244e-02, 6.4539e-01, 2.1404e-01],\n",
      "          [1.9790e-01, 4.3780e-01, 1.0726e-01]],\n",
      "\n",
      "         [[8.1458e-03, 3.0859e-01, 4.2641e-01],\n",
      "          [2.8758e-01, 1.3115e-01, 2.3383e-01],\n",
      "          [2.9775e-01, 2.3621e-01, 5.2035e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.5700e-02, 3.6878e-02, 4.1671e-02],\n",
      "          [1.3005e-02, 3.9932e-02, 5.1004e-02],\n",
      "          [3.9974e-02, 3.2413e-02, 1.7654e-03]],\n",
      "\n",
      "         [[4.0319e-02, 3.8699e-02, 2.7542e-02],\n",
      "          [1.5086e-02, 1.1302e-02, 1.0610e-02],\n",
      "          [2.1409e-02, 1.9837e-02, 1.1533e-02]],\n",
      "\n",
      "         [[4.3509e-02, 2.1615e-03, 2.3126e-02],\n",
      "          [1.0242e-02, 1.6768e-03, 2.6938e-02],\n",
      "          [1.5638e-02, 6.6546e-03, 2.7058e-02]]],\n",
      "\n",
      "\n",
      "        [[[2.1901e-02, 4.5846e-02, 2.7489e-02],\n",
      "          [4.6927e-02, 3.3337e-02, 3.2017e-02],\n",
      "          [2.9073e-02, 3.0201e-02, 3.3771e-02]],\n",
      "\n",
      "         [[1.9644e-02, 3.1516e-02, 2.4462e-02],\n",
      "          [4.6326e-02, 3.8523e-02, 3.7388e-02],\n",
      "          [2.7189e-02, 1.6532e-02, 2.8886e-02]],\n",
      "\n",
      "         [[1.6788e-03, 1.0241e-02, 4.2266e-03],\n",
      "          [8.8524e-03, 1.5414e-02, 9.9854e-03],\n",
      "          [7.8693e-03, 1.5705e-02, 3.2219e-03]]],\n",
      "\n",
      "\n",
      "        [[[1.0056e+00, 2.4056e+00, 1.1158e+00],\n",
      "          [8.6002e-01, 2.1854e+00, 1.4026e+00],\n",
      "          [9.2443e-01, 1.6883e+00, 4.7237e-01]],\n",
      "\n",
      "         [[6.8360e-01, 4.0090e-01, 1.3528e-03],\n",
      "          [2.0366e-01, 3.5436e+00, 1.2238e+00],\n",
      "          [3.6261e-01, 7.0936e-01, 1.1243e+00]],\n",
      "\n",
      "         [[8.8290e-01, 4.0079e-01, 1.0134e+00],\n",
      "          [1.3305e+00, 2.3017e+00, 4.2686e-01],\n",
      "          [1.6706e+00, 9.7788e-01, 1.1195e+00]]],\n",
      "\n",
      "\n",
      "        [[[5.4312e-02, 8.6090e-03, 2.4351e-02],\n",
      "          [6.3750e-02, 6.5282e-02, 2.2048e-02],\n",
      "          [7.5692e-02, 8.4451e-02, 1.1337e-02]],\n",
      "\n",
      "         [[1.4867e-02, 2.4285e-02, 4.3176e-02],\n",
      "          [3.7581e-02, 7.2515e-03, 3.1543e-02],\n",
      "          [3.3170e-02, 2.1327e-02, 4.6120e-02]],\n",
      "\n",
      "         [[4.1705e-02, 5.2066e-02, 7.2962e-03],\n",
      "          [1.1358e-01, 6.3965e-02, 6.2329e-02],\n",
      "          [6.2877e-02, 5.6932e-02, 2.9519e-02]]],\n",
      "\n",
      "\n",
      "        [[[5.9448e-03, 5.8302e-02, 3.4240e-02],\n",
      "          [7.5851e-02, 1.1081e-01, 7.4005e-02],\n",
      "          [8.1940e-02, 1.6751e-01, 1.4184e-01]],\n",
      "\n",
      "         [[3.2585e-02, 2.6916e-02, 8.4491e-03],\n",
      "          [2.9355e-02, 7.5008e-03, 5.7408e-02],\n",
      "          [5.0336e-02, 7.4177e-02, 7.2626e-02]],\n",
      "\n",
      "         [[1.3601e-01, 1.4219e-01, 1.4420e-01],\n",
      "          [1.6022e-01, 1.9449e-01, 1.9021e-01],\n",
      "          [1.4729e-01, 1.2629e-01, 7.8182e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.6971e-01, 5.3022e-01, 4.1525e-01],\n",
      "          [2.4496e-02, 9.9978e-02, 1.1084e-01],\n",
      "          [3.8392e-02, 2.2872e-01, 1.2878e-01]],\n",
      "\n",
      "         [[5.2284e-02, 2.1919e-01, 1.2575e-01],\n",
      "          [2.2093e-01, 1.0492e-01, 2.4164e-01],\n",
      "          [2.3907e-01, 4.4730e-01, 3.4553e-01]],\n",
      "\n",
      "         [[3.7679e-02, 4.8524e-01, 4.1411e-01],\n",
      "          [4.2741e-02, 2.0354e-01, 8.9032e-02],\n",
      "          [2.2522e-01, 3.4188e-01, 8.4863e-02]]],\n",
      "\n",
      "\n",
      "        [[[8.9823e-02, 7.8574e-02, 3.8589e-02],\n",
      "          [3.2025e-01, 4.0571e-01, 3.9976e-03],\n",
      "          [6.7183e-02, 1.5645e-02, 6.7122e-02]],\n",
      "\n",
      "         [[2.3422e-01, 2.1740e-01, 2.0120e-01],\n",
      "          [1.3117e-01, 1.6732e-01, 2.5678e-02],\n",
      "          [3.0015e-01, 4.3975e-02, 1.2065e-01]],\n",
      "\n",
      "         [[1.6765e-01, 1.0013e-02, 2.8257e-03],\n",
      "          [3.7092e-01, 4.5512e-01, 1.1313e-01],\n",
      "          [2.0985e-01, 1.1412e-01, 1.0036e-01]]],\n",
      "\n",
      "\n",
      "        [[[2.6841e-02, 1.7117e+00, 8.6741e-02],\n",
      "          [1.3121e+00, 1.2291e+00, 6.4874e-02],\n",
      "          [9.9951e-01, 6.4167e-01, 2.4084e-01]],\n",
      "\n",
      "         [[1.3628e-01, 1.8126e+00, 4.0595e-02],\n",
      "          [1.0235e+00, 9.3970e-01, 8.1809e-02],\n",
      "          [9.0023e-01, 6.5446e-01, 6.9980e-02]],\n",
      "\n",
      "         [[4.0239e-01, 1.2618e+00, 4.5563e-01],\n",
      "          [1.1662e+00, 1.9782e-01, 5.8293e-01],\n",
      "          [1.2173e-01, 4.4611e-01, 5.9189e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.3027e-01, 3.9003e-01, 2.2534e-01],\n",
      "          [1.7970e-02, 2.1987e-01, 1.0943e-01],\n",
      "          [1.7172e-02, 2.0878e-01, 7.3153e-02]],\n",
      "\n",
      "         [[1.8515e-02, 2.4900e-01, 8.6269e-02],\n",
      "          [3.0646e-01, 9.1273e-02, 8.3107e-02],\n",
      "          [2.0480e-01, 4.8650e-02, 9.5074e-02]],\n",
      "\n",
      "         [[1.3692e-03, 1.7247e-01, 1.2015e-01],\n",
      "          [2.3281e-01, 2.1819e-01, 1.5525e-01],\n",
      "          [1.9633e-01, 1.3864e-01, 7.4082e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.2557e-02, 3.1138e-02, 1.0365e-02],\n",
      "          [1.9293e-02, 1.3467e-02, 2.2285e-02],\n",
      "          [7.7738e-03, 3.2666e-02, 1.4693e-02]],\n",
      "\n",
      "         [[1.1173e-03, 3.8313e-02, 2.8336e-02],\n",
      "          [4.0353e-02, 4.7695e-03, 4.9794e-02],\n",
      "          [3.6652e-02, 2.5865e-04, 5.8756e-04]],\n",
      "\n",
      "         [[8.0181e-02, 7.1608e-02, 5.9699e-02],\n",
      "          [7.4868e-02, 7.3645e-02, 5.0822e-02],\n",
      "          [8.3443e-02, 9.7780e-02, 7.1558e-02]]],\n",
      "\n",
      "\n",
      "        [[[5.6206e-01, 1.8071e-01, 8.4760e-02],\n",
      "          [2.6192e-01, 3.2753e-01, 4.6803e-01],\n",
      "          [4.6039e-01, 1.7820e-01, 7.5376e-02]],\n",
      "\n",
      "         [[8.0002e-02, 3.2034e-01, 1.7858e-01],\n",
      "          [2.2350e-01, 6.9451e-01, 5.1375e-01],\n",
      "          [1.2414e-01, 5.6669e-02, 1.2023e-01]],\n",
      "\n",
      "         [[2.1229e-02, 5.5112e-03, 2.0130e-01],\n",
      "          [1.2144e-01, 3.4650e-01, 9.4869e-02],\n",
      "          [1.2389e-01, 2.0146e-01, 3.1109e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.7502e-01, 9.1670e-02, 2.1088e-01],\n",
      "          [2.8641e-02, 3.1747e-01, 3.7790e-01],\n",
      "          [7.2507e-02, 2.0461e-01, 1.2581e-01]],\n",
      "\n",
      "         [[5.0066e-01, 3.7653e-01, 1.2838e-01],\n",
      "          [2.8321e-01, 4.9098e-02, 1.5571e-02],\n",
      "          [1.8316e-01, 1.5248e-01, 9.5339e-02]],\n",
      "\n",
      "         [[2.7486e-01, 9.4143e-02, 9.1351e-02],\n",
      "          [1.0689e-01, 3.2387e-01, 3.3587e-01],\n",
      "          [9.8001e-02, 2.3413e-01, 1.2845e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.2751e-01, 1.4864e-01, 1.2997e-01],\n",
      "          [2.6275e-02, 7.7811e-02, 6.9673e-03],\n",
      "          [1.2868e-01, 1.1836e-01, 2.4704e-03]],\n",
      "\n",
      "         [[2.5720e-02, 3.0475e-02, 5.9357e-02],\n",
      "          [9.2802e-02, 1.3511e-01, 1.3715e-01],\n",
      "          [1.1138e-01, 2.2502e-01, 1.2065e-01]],\n",
      "\n",
      "         [[1.9671e-02, 1.3743e-02, 5.9636e-04],\n",
      "          [7.6128e-02, 1.4708e-02, 1.6837e-02],\n",
      "          [4.3527e-02, 7.4252e-02, 3.1806e-02]]]])\n",
      "torch.Size([3, 3, 3])\n",
      "tensor([[[0.1087, 0.1202, 0.0858],\n",
      "         [0.0378, 0.1653, 0.0694],\n",
      "         [0.0741, 0.1444, 0.0743]],\n",
      "\n",
      "        [[0.0463, 0.1665, 0.0419],\n",
      "         [0.1120, 0.0981, 0.0696],\n",
      "         [0.1537, 0.0654, 0.0952]],\n",
      "\n",
      "        [[0.0618, 0.0888, 0.1057],\n",
      "         [0.1175, 0.1962, 0.1040],\n",
      "         [0.1228, 0.1325, 0.0843]]], dtype=torch.float64)\n",
      "torch.Size([32, 16, 3, 3])\n",
      "tensor([[[[1.2187e-02, 2.4174e-02, 3.4658e-02],\n",
      "          [2.0033e-02, 1.3113e-02, 1.4219e-02],\n",
      "          [3.6555e-02, 5.1472e-02, 2.4247e-02]],\n",
      "\n",
      "         [[3.9631e-02, 4.7774e-02, 1.5035e-01],\n",
      "          [6.8374e-02, 5.8391e-02, 6.2161e-02],\n",
      "          [3.6774e-02, 2.7825e-02, 1.7207e-01]],\n",
      "\n",
      "         [[2.3930e-02, 1.5253e-02, 1.2452e-02],\n",
      "          [1.2216e-02, 2.1968e-02, 9.6516e-03],\n",
      "          [5.0575e-02, 6.4563e-02, 4.9135e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[9.8955e-02, 4.2933e-02, 2.2632e-02],\n",
      "          [1.4173e-03, 1.2891e-02, 4.9718e-02],\n",
      "          [2.4335e-02, 3.0209e-02, 7.0460e-02]],\n",
      "\n",
      "         [[2.9843e-02, 1.7786e-02, 2.9700e-02],\n",
      "          [5.6517e-02, 5.9112e-02, 2.5648e-02],\n",
      "          [4.7891e-02, 4.7309e-02, 3.7389e-02]],\n",
      "\n",
      "         [[1.9791e-02, 2.2224e-02, 2.3847e-02],\n",
      "          [2.2497e-02, 2.8678e-02, 3.9834e-03],\n",
      "          [1.5986e-02, 1.7098e-02, 3.5011e-02]]],\n",
      "\n",
      "\n",
      "        [[[2.0931e-03, 1.8009e-02, 1.9209e-02],\n",
      "          [1.2912e-02, 2.1106e-02, 3.1420e-02],\n",
      "          [9.4782e-03, 1.5930e-02, 4.7743e-03]],\n",
      "\n",
      "         [[1.3843e-02, 5.2891e-02, 5.5726e-02],\n",
      "          [6.4907e-02, 5.6613e-03, 1.2124e-01],\n",
      "          [1.1461e-01, 7.8162e-02, 2.1903e-01]],\n",
      "\n",
      "         [[2.3209e-02, 9.0071e-02, 9.3177e-02],\n",
      "          [5.8446e-02, 1.6596e-01, 1.7570e-01],\n",
      "          [4.1542e-02, 9.9064e-02, 9.9570e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.7157e-02, 1.9357e-02, 5.7963e-02],\n",
      "          [7.9551e-02, 1.1822e-01, 4.1178e-03],\n",
      "          [1.0597e-01, 1.1474e-01, 2.4270e-02]],\n",
      "\n",
      "         [[2.4040e-02, 3.4456e-02, 9.8859e-04],\n",
      "          [1.8750e-02, 5.9319e-03, 4.8593e-02],\n",
      "          [1.1432e-02, 4.0530e-02, 1.0182e-01]],\n",
      "\n",
      "         [[1.6604e-02, 4.2106e-02, 4.2686e-02],\n",
      "          [2.4935e-02, 4.7752e-02, 5.3396e-02],\n",
      "          [2.5969e-04, 3.5687e-02, 3.0661e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.9914e-02, 1.7194e-02, 2.7904e-02],\n",
      "          [2.5617e-02, 2.3313e-02, 2.9944e-03],\n",
      "          [6.3014e-02, 5.6242e-02, 2.5167e-02]],\n",
      "\n",
      "         [[7.1292e-02, 2.7292e-01, 3.3823e-02],\n",
      "          [1.4713e-01, 3.4479e-02, 1.3056e-01],\n",
      "          [1.9868e-01, 2.5717e-01, 5.9735e-02]],\n",
      "\n",
      "         [[1.1405e-03, 4.0509e-02, 4.5646e-02],\n",
      "          [3.6798e-02, 1.0074e-02, 1.9105e-03],\n",
      "          [4.1945e-02, 6.8561e-03, 5.1169e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.6513e-02, 1.2318e-03, 6.9998e-02],\n",
      "          [5.8530e-04, 4.4724e-02, 1.1806e-02],\n",
      "          [3.2996e-02, 3.0424e-02, 1.9917e-02]],\n",
      "\n",
      "         [[1.8776e-02, 4.5927e-02, 4.4721e-02],\n",
      "          [2.0185e-02, 2.0467e-02, 1.1614e-02],\n",
      "          [5.9734e-02, 7.9546e-04, 1.9838e-02]],\n",
      "\n",
      "         [[1.4571e-02, 5.2664e-02, 4.4086e-02],\n",
      "          [3.2435e-03, 9.1382e-03, 1.0858e-02],\n",
      "          [3.2804e-02, 1.4327e-02, 1.5836e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[7.1488e-03, 3.3063e-02, 2.5273e-02],\n",
      "          [3.2981e-02, 2.4653e-02, 4.3702e-02],\n",
      "          [2.4437e-02, 1.8238e-03, 1.1124e-02]],\n",
      "\n",
      "         [[6.9431e-02, 2.1241e-01, 4.9299e-02],\n",
      "          [6.2549e-02, 1.6096e-01, 2.4042e-02],\n",
      "          [1.4843e-01, 1.5690e-02, 1.4856e-01]],\n",
      "\n",
      "         [[4.9344e-02, 4.7000e-02, 1.5201e-02],\n",
      "          [6.1873e-02, 6.6714e-02, 4.5688e-02],\n",
      "          [5.3265e-02, 4.6375e-02, 4.3972e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.9043e-02, 1.0850e-02, 2.3948e-02],\n",
      "          [6.1278e-02, 5.3833e-02, 6.3155e-02],\n",
      "          [7.5824e-02, 1.7109e-02, 5.5101e-02]],\n",
      "\n",
      "         [[2.5996e-02, 2.3650e-02, 2.8316e-02],\n",
      "          [1.0216e-02, 6.7057e-03, 4.9795e-02],\n",
      "          [3.3131e-02, 1.1588e-02, 6.6429e-02]],\n",
      "\n",
      "         [[3.2425e-02, 3.8520e-02, 5.1754e-02],\n",
      "          [4.9697e-02, 5.6237e-02, 6.5134e-02],\n",
      "          [3.5109e-02, 2.5133e-02, 3.9943e-02]]],\n",
      "\n",
      "\n",
      "        [[[7.3639e-02, 6.6702e-02, 3.8392e-02],\n",
      "          [5.8478e-02, 8.3546e-02, 5.0144e-02],\n",
      "          [6.8714e-02, 5.1076e-02, 3.7735e-02]],\n",
      "\n",
      "         [[3.3578e-03, 6.8993e-02, 9.2857e-02],\n",
      "          [2.8164e-02, 5.9306e-02, 5.8406e-02],\n",
      "          [2.8756e-02, 8.2397e-02, 7.6568e-02]],\n",
      "\n",
      "         [[5.0990e-03, 2.9464e-03, 1.9444e-02],\n",
      "          [4.4702e-02, 8.4772e-03, 1.1805e-02],\n",
      "          [2.1512e-02, 9.7380e-03, 1.1163e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[9.5374e-04, 4.9154e-02, 1.9071e-03],\n",
      "          [5.0289e-03, 1.5338e-02, 5.2688e-02],\n",
      "          [1.0666e-02, 1.4715e-03, 1.2324e-02]],\n",
      "\n",
      "         [[3.3022e-02, 2.7874e-02, 2.5458e-02],\n",
      "          [1.3721e-02, 6.7472e-03, 8.9389e-03],\n",
      "          [2.9119e-02, 2.0293e-02, 2.1443e-02]],\n",
      "\n",
      "         [[1.0397e-02, 3.9872e-03, 1.3271e-02],\n",
      "          [1.2606e-02, 1.2700e-02, 1.0875e-02],\n",
      "          [1.8128e-03, 1.8292e-02, 2.2459e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.0010e-02, 1.1893e-02, 8.4997e-03],\n",
      "          [6.4890e-03, 3.5351e-02, 3.4438e-02],\n",
      "          [3.8582e-03, 2.7548e-02, 3.4455e-02]],\n",
      "\n",
      "         [[6.8324e-02, 4.7313e-02, 8.4657e-02],\n",
      "          [1.7176e-01, 1.0395e-01, 3.4923e-02],\n",
      "          [1.3654e-01, 5.4349e-02, 1.9235e-02]],\n",
      "\n",
      "         [[1.5885e-02, 1.6005e-02, 1.6330e-02],\n",
      "          [7.1142e-03, 1.7997e-02, 2.4182e-02],\n",
      "          [2.0082e-02, 2.0468e-02, 3.4177e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.0756e-02, 2.1654e-02, 3.4218e-02],\n",
      "          [8.6183e-03, 1.9482e-02, 4.4931e-02],\n",
      "          [7.5324e-03, 3.9652e-03, 2.5508e-02]],\n",
      "\n",
      "         [[1.6454e-02, 9.9989e-03, 1.6817e-02],\n",
      "          [1.3278e-02, 1.9120e-03, 1.6868e-02],\n",
      "          [1.1109e-02, 1.0898e-02, 1.9519e-02]],\n",
      "\n",
      "         [[3.2846e-02, 7.7447e-03, 6.5346e-04],\n",
      "          [1.4549e-02, 1.4869e-02, 1.3555e-02],\n",
      "          [1.2801e-02, 1.5374e-02, 1.6682e-02]]]])\n",
      "torch.Size([16, 3, 3])\n",
      "tensor([[[0.0136, 0.0164, 0.0214],\n",
      "         [0.0203, 0.0206, 0.0185],\n",
      "         [0.0235, 0.0169, 0.0238]],\n",
      "\n",
      "        [[0.0619, 0.0649, 0.0590],\n",
      "         [0.0664, 0.0835, 0.0611],\n",
      "         [0.0702, 0.0561, 0.0611]],\n",
      "\n",
      "        [[0.0253, 0.0234, 0.0226],\n",
      "         [0.0221, 0.0259, 0.0187],\n",
      "         [0.0304, 0.0402, 0.0218]],\n",
      "\n",
      "        [[0.0117, 0.0100, 0.0138],\n",
      "         [0.0115, 0.0122, 0.0107],\n",
      "         [0.0102, 0.0155, 0.0157]],\n",
      "\n",
      "        [[0.0160, 0.0131, 0.0209],\n",
      "         [0.0178, 0.0150, 0.0213],\n",
      "         [0.0215, 0.0210, 0.0152]],\n",
      "\n",
      "        [[0.0696, 0.0727, 0.0875],\n",
      "         [0.0806, 0.0772, 0.1081],\n",
      "         [0.0607, 0.0465, 0.0438]],\n",
      "\n",
      "        [[0.0161, 0.0107, 0.0144],\n",
      "         [0.0174, 0.0145, 0.0136],\n",
      "         [0.0125, 0.0195, 0.0141]],\n",
      "\n",
      "        [[0.0152, 0.0283, 0.0170],\n",
      "         [0.0273, 0.0242, 0.0334],\n",
      "         [0.0235, 0.0299, 0.0339]],\n",
      "\n",
      "        [[0.0504, 0.0315, 0.0475],\n",
      "         [0.0329, 0.0375, 0.0324],\n",
      "         [0.0435, 0.0328, 0.0485]],\n",
      "\n",
      "        [[0.0128, 0.0180, 0.0167],\n",
      "         [0.0184, 0.0214, 0.0228],\n",
      "         [0.0303, 0.0290, 0.0245]],\n",
      "\n",
      "        [[0.0356, 0.0459, 0.0330],\n",
      "         [0.0509, 0.0515, 0.0369],\n",
      "         [0.0417, 0.0511, 0.0532]],\n",
      "\n",
      "        [[0.0250, 0.0382, 0.0454],\n",
      "         [0.0203, 0.0426, 0.0359],\n",
      "         [0.0257, 0.0411, 0.0373]],\n",
      "\n",
      "        [[0.0175, 0.0112, 0.0115],\n",
      "         [0.0137, 0.0162, 0.0110],\n",
      "         [0.0110, 0.0118, 0.0114]],\n",
      "\n",
      "        [[0.0276, 0.0230, 0.0331],\n",
      "         [0.0299, 0.0203, 0.0302],\n",
      "         [0.0264, 0.0196, 0.0357]],\n",
      "\n",
      "        [[0.0250, 0.0298, 0.0276],\n",
      "         [0.0316, 0.0377, 0.0297],\n",
      "         [0.0314, 0.0197, 0.0257]],\n",
      "\n",
      "        [[0.0172, 0.0179, 0.0216],\n",
      "         [0.0155, 0.0120, 0.0194],\n",
      "         [0.0199, 0.0184, 0.0236]]], dtype=torch.float64)\n",
      "torch.Size([64, 32, 3, 3])\n",
      "tensor([[[[1.1406e-02, 2.1902e-02, 2.6791e-02],\n",
      "          [1.5695e-02, 2.0791e-03, 9.5946e-03],\n",
      "          [2.1113e-04, 2.3909e-02, 3.6909e-02]],\n",
      "\n",
      "         [[1.6233e-02, 2.5718e-02, 2.2276e-02],\n",
      "          [1.3741e-02, 1.8260e-02, 1.5646e-02],\n",
      "          [1.7652e-02, 1.6825e-02, 1.2427e-02]],\n",
      "\n",
      "         [[1.8604e-02, 3.0389e-02, 3.0248e-03],\n",
      "          [1.0428e-02, 5.0272e-03, 2.5707e-02],\n",
      "          [2.8008e-02, 1.2935e-02, 9.5845e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.0820e-02, 5.7882e-03, 4.8505e-03],\n",
      "          [1.7307e-02, 3.5558e-03, 7.4647e-04],\n",
      "          [1.3901e-02, 1.5052e-02, 2.9653e-02]],\n",
      "\n",
      "         [[1.5493e-04, 3.1547e-02, 3.0940e-02],\n",
      "          [7.9821e-04, 3.7940e-02, 1.1637e-02],\n",
      "          [9.2968e-03, 9.1166e-03, 1.7551e-02]],\n",
      "\n",
      "         [[6.0879e-03, 2.7778e-02, 2.8698e-02],\n",
      "          [1.4410e-02, 1.0937e-02, 6.1778e-03],\n",
      "          [2.3569e-02, 1.8273e-02, 3.7974e-03]]],\n",
      "\n",
      "\n",
      "        [[[4.1371e-02, 7.3508e-02, 4.9829e-02],\n",
      "          [5.3140e-02, 8.0515e-02, 9.6568e-02],\n",
      "          [3.5381e-02, 1.7416e-02, 2.6431e-02]],\n",
      "\n",
      "         [[4.3466e-02, 1.8258e-02, 5.8686e-03],\n",
      "          [1.4343e-02, 5.5962e-03, 2.5541e-03],\n",
      "          [8.1384e-03, 1.6510e-02, 1.5698e-02]],\n",
      "\n",
      "         [[6.6117e-02, 5.1759e-02, 5.1782e-02],\n",
      "          [6.4430e-02, 1.1223e-02, 5.7403e-02],\n",
      "          [2.4256e-02, 4.6763e-02, 3.3978e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.7321e-03, 3.0472e-04, 1.4085e-02],\n",
      "          [6.1579e-02, 6.1217e-03, 1.2677e-02],\n",
      "          [6.2456e-02, 3.2853e-02, 4.6003e-03]],\n",
      "\n",
      "         [[6.2966e-04, 8.1496e-03, 4.0556e-03],\n",
      "          [1.0034e-03, 6.7859e-03, 2.0684e-02],\n",
      "          [6.8227e-04, 1.5920e-02, 3.1093e-03]],\n",
      "\n",
      "         [[3.1580e-02, 1.3815e-02, 1.8934e-02],\n",
      "          [2.4948e-02, 1.3538e-02, 2.9819e-02],\n",
      "          [9.8759e-03, 8.4276e-03, 2.0672e-02]]],\n",
      "\n",
      "\n",
      "        [[[7.3112e-02, 3.5463e-02, 5.0525e-02],\n",
      "          [4.1113e-02, 7.1745e-02, 1.6679e-03],\n",
      "          [1.8618e-02, 4.2539e-02, 4.0870e-02]],\n",
      "\n",
      "         [[1.4099e-02, 1.9280e-02, 2.6435e-02],\n",
      "          [2.9389e-02, 3.9474e-03, 2.4836e-02],\n",
      "          [2.9338e-02, 2.7191e-02, 3.4440e-02]],\n",
      "\n",
      "         [[1.9353e-02, 5.0421e-02, 6.1378e-02],\n",
      "          [5.2298e-02, 2.6231e-02, 1.2815e-02],\n",
      "          [2.5978e-02, 5.3055e-03, 4.5308e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2.8682e-02, 2.1060e-02, 1.4170e-03],\n",
      "          [5.1942e-03, 1.1915e-03, 3.9628e-03],\n",
      "          [3.2335e-03, 2.3433e-03, 3.1709e-02]],\n",
      "\n",
      "         [[5.5142e-03, 1.2462e-02, 1.6721e-02],\n",
      "          [1.6479e-03, 1.7413e-02, 1.6935e-02],\n",
      "          [2.2477e-03, 5.1005e-03, 1.2590e-02]],\n",
      "\n",
      "         [[4.5681e-03, 1.7779e-02, 2.3714e-02],\n",
      "          [5.5862e-03, 9.8061e-03, 3.3900e-02],\n",
      "          [7.5198e-03, 1.4593e-02, 4.6371e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1.4478e-02, 1.4478e-02, 7.3393e-03],\n",
      "          [2.1161e-02, 1.8614e-02, 2.5134e-03],\n",
      "          [5.6831e-03, 1.0057e-02, 2.6410e-03]],\n",
      "\n",
      "         [[3.3027e-02, 3.3650e-02, 2.4011e-02],\n",
      "          [1.1033e-02, 4.6836e-03, 6.1084e-03],\n",
      "          [5.5402e-03, 1.1162e-02, 1.1480e-02]],\n",
      "\n",
      "         [[3.4260e-02, 2.5277e-02, 3.2532e-02],\n",
      "          [1.6699e-02, 3.5527e-02, 2.2694e-02],\n",
      "          [3.4649e-02, 3.4313e-02, 4.1805e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.3262e-02, 5.1704e-02, 1.7703e-02],\n",
      "          [9.7961e-03, 3.8138e-02, 4.6275e-02],\n",
      "          [2.2147e-02, 2.4225e-02, 7.3604e-03]],\n",
      "\n",
      "         [[4.6185e-03, 6.6590e-04, 1.7406e-02],\n",
      "          [8.8253e-03, 3.2683e-03, 1.2868e-02],\n",
      "          [3.2721e-02, 3.5779e-02, 1.9776e-02]],\n",
      "\n",
      "         [[2.7860e-02, 1.0777e-02, 1.1795e-02],\n",
      "          [1.9265e-02, 1.7512e-02, 3.0163e-02],\n",
      "          [3.6018e-02, 3.4038e-02, 3.5473e-03]]],\n",
      "\n",
      "\n",
      "        [[[8.2782e-02, 3.1900e-02, 8.7766e-02],\n",
      "          [5.8794e-02, 1.5178e-02, 1.0407e-01],\n",
      "          [2.9432e-02, 3.7025e-02, 5.5479e-02]],\n",
      "\n",
      "         [[1.7202e-02, 2.0235e-02, 7.9733e-03],\n",
      "          [5.0401e-02, 3.8838e-02, 3.8912e-02],\n",
      "          [7.4986e-02, 1.3403e-02, 5.3004e-02]],\n",
      "\n",
      "         [[1.2267e-02, 1.5347e-01, 1.3408e-02],\n",
      "          [6.4082e-02, 1.1614e-01, 2.1884e-01],\n",
      "          [8.5302e-03, 1.4477e-02, 3.9914e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.5402e-02, 6.7632e-02, 4.8049e-02],\n",
      "          [5.1039e-03, 9.3905e-02, 5.8246e-02],\n",
      "          [7.5158e-02, 6.5126e-02, 2.2343e-02]],\n",
      "\n",
      "         [[3.0506e-03, 2.9237e-02, 5.1096e-02],\n",
      "          [4.8221e-02, 1.9790e-02, 3.5264e-02],\n",
      "          [3.6267e-02, 2.0444e-02, 2.2327e-02]],\n",
      "\n",
      "         [[2.0377e-03, 5.6576e-02, 1.6493e-02],\n",
      "          [2.2919e-03, 1.8741e-02, 2.7645e-02],\n",
      "          [2.3331e-02, 1.1193e-02, 1.0625e-02]]],\n",
      "\n",
      "\n",
      "        [[[8.9789e-02, 1.6635e-02, 6.8089e-02],\n",
      "          [6.2150e-02, 1.5684e-02, 9.4264e-02],\n",
      "          [1.7971e-02, 1.3950e-02, 2.7490e-02]],\n",
      "\n",
      "         [[5.5965e-04, 9.8674e-03, 4.8686e-03],\n",
      "          [3.5860e-02, 1.7353e-02, 1.2897e-02],\n",
      "          [5.7854e-03, 9.9180e-03, 1.5010e-02]],\n",
      "\n",
      "         [[3.5332e-02, 7.3789e-02, 2.4563e-02],\n",
      "          [1.1313e-01, 6.6086e-02, 5.0429e-02],\n",
      "          [5.3859e-02, 7.5309e-02, 6.7722e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.8976e-02, 4.1253e-02, 4.7677e-03],\n",
      "          [2.4727e-02, 2.6995e-02, 4.6999e-02],\n",
      "          [4.5112e-03, 1.2355e-02, 4.6449e-02]],\n",
      "\n",
      "         [[5.1028e-03, 6.7399e-03, 2.9538e-03],\n",
      "          [8.2308e-03, 1.9350e-02, 1.9457e-02],\n",
      "          [1.8933e-03, 1.5557e-02, 6.2735e-03]],\n",
      "\n",
      "         [[2.4423e-02, 2.2489e-02, 1.9783e-02],\n",
      "          [2.5596e-02, 3.4901e-03, 5.3008e-02],\n",
      "          [6.0475e-02, 2.0015e-02, 9.1424e-03]]]])\n",
      "torch.Size([32, 3, 3])\n",
      "tensor([[[0.0216, 0.0200, 0.0219],\n",
      "         [0.0185, 0.0254, 0.0228],\n",
      "         [0.0188, 0.0313, 0.0274]],\n",
      "\n",
      "        [[0.0167, 0.0188, 0.0189],\n",
      "         [0.0154, 0.0142, 0.0149],\n",
      "         [0.0192, 0.0171, 0.0144]],\n",
      "\n",
      "        [[0.0266, 0.0264, 0.0307],\n",
      "         [0.0302, 0.0535, 0.0436],\n",
      "         [0.0291, 0.0236, 0.0310]],\n",
      "\n",
      "        [[0.0163, 0.0153, 0.0152],\n",
      "         [0.0187, 0.0197, 0.0161],\n",
      "         [0.0150, 0.0176, 0.0161]],\n",
      "\n",
      "        [[0.0197, 0.0241, 0.0153],\n",
      "         [0.0192, 0.0228, 0.0197],\n",
      "         [0.0221, 0.0127, 0.0244]],\n",
      "\n",
      "        [[0.0128, 0.0130, 0.0096],\n",
      "         [0.0145, 0.0152, 0.0133],\n",
      "         [0.0132, 0.0143, 0.0162]],\n",
      "\n",
      "        [[0.0198, 0.0244, 0.0167],\n",
      "         [0.0202, 0.0271, 0.0216],\n",
      "         [0.0302, 0.0319, 0.0251]],\n",
      "\n",
      "        [[0.0249, 0.0166, 0.0214],\n",
      "         [0.0350, 0.0317, 0.0226],\n",
      "         [0.0231, 0.0350, 0.0237]],\n",
      "\n",
      "        [[0.0228, 0.0200, 0.0255],\n",
      "         [0.0219, 0.0281, 0.0261],\n",
      "         [0.0184, 0.0245, 0.0265]],\n",
      "\n",
      "        [[0.0087, 0.0111, 0.0102],\n",
      "         [0.0109, 0.0101, 0.0092],\n",
      "         [0.0114, 0.0093, 0.0107]],\n",
      "\n",
      "        [[0.0180, 0.0205, 0.0161],\n",
      "         [0.0196, 0.0170, 0.0168],\n",
      "         [0.0208, 0.0154, 0.0153]],\n",
      "\n",
      "        [[0.0185, 0.0183, 0.0188],\n",
      "         [0.0252, 0.0274, 0.0211],\n",
      "         [0.0192, 0.0189, 0.0184]],\n",
      "\n",
      "        [[0.0290, 0.0274, 0.0256],\n",
      "         [0.0324, 0.0504, 0.0303],\n",
      "         [0.0211, 0.0259, 0.0252]],\n",
      "\n",
      "        [[0.0176, 0.0222, 0.0218],\n",
      "         [0.0203, 0.0197, 0.0210],\n",
      "         [0.0208, 0.0166, 0.0183]],\n",
      "\n",
      "        [[0.0065, 0.0067, 0.0096],\n",
      "         [0.0078, 0.0108, 0.0077],\n",
      "         [0.0070, 0.0067, 0.0070]],\n",
      "\n",
      "        [[0.0134, 0.0129, 0.0097],\n",
      "         [0.0113, 0.0132, 0.0111],\n",
      "         [0.0124, 0.0134, 0.0098]],\n",
      "\n",
      "        [[0.0131, 0.0137, 0.0089],\n",
      "         [0.0164, 0.0163, 0.0126],\n",
      "         [0.0116, 0.0172, 0.0109]],\n",
      "\n",
      "        [[0.0076, 0.0138, 0.0096],\n",
      "         [0.0105, 0.0139, 0.0078],\n",
      "         [0.0131, 0.0111, 0.0106]],\n",
      "\n",
      "        [[0.0181, 0.0193, 0.0172],\n",
      "         [0.0194, 0.0241, 0.0183],\n",
      "         [0.0182, 0.0190, 0.0176]],\n",
      "\n",
      "        [[0.0285, 0.0255, 0.0258],\n",
      "         [0.0301, 0.0267, 0.0287],\n",
      "         [0.0273, 0.0227, 0.0176]],\n",
      "\n",
      "        [[0.0231, 0.0208, 0.0212],\n",
      "         [0.0254, 0.0265, 0.0263],\n",
      "         [0.0182, 0.0222, 0.0190]],\n",
      "\n",
      "        [[0.0106, 0.0161, 0.0166],\n",
      "         [0.0154, 0.0143, 0.0129],\n",
      "         [0.0132, 0.0147, 0.0153]],\n",
      "\n",
      "        [[0.0097, 0.0122, 0.0119],\n",
      "         [0.0104, 0.0139, 0.0103],\n",
      "         [0.0092, 0.0110, 0.0104]],\n",
      "\n",
      "        [[0.0200, 0.0254, 0.0222],\n",
      "         [0.0272, 0.0306, 0.0292],\n",
      "         [0.0213, 0.0177, 0.0248]],\n",
      "\n",
      "        [[0.0253, 0.0341, 0.0241],\n",
      "         [0.0231, 0.0373, 0.0235],\n",
      "         [0.0276, 0.0262, 0.0214]],\n",
      "\n",
      "        [[0.0102, 0.0136, 0.0136],\n",
      "         [0.0159, 0.0186, 0.0154],\n",
      "         [0.0143, 0.0180, 0.0149]],\n",
      "\n",
      "        [[0.0083, 0.0084, 0.0070],\n",
      "         [0.0087, 0.0105, 0.0078],\n",
      "         [0.0101, 0.0072, 0.0069]],\n",
      "\n",
      "        [[0.0259, 0.0250, 0.0181],\n",
      "         [0.0236, 0.0320, 0.0259],\n",
      "         [0.0247, 0.0191, 0.0236]],\n",
      "\n",
      "        [[0.0075, 0.0093, 0.0101],\n",
      "         [0.0119, 0.0106, 0.0090],\n",
      "         [0.0103, 0.0100, 0.0080]],\n",
      "\n",
      "        [[0.0172, 0.0176, 0.0179],\n",
      "         [0.0196, 0.0235, 0.0181],\n",
      "         [0.0198, 0.0225, 0.0153]],\n",
      "\n",
      "        [[0.0053, 0.0091, 0.0069],\n",
      "         [0.0101, 0.0116, 0.0112],\n",
      "         [0.0096, 0.0081, 0.0087]],\n",
      "\n",
      "        [[0.0146, 0.0144, 0.0167],\n",
      "         [0.0118, 0.0113, 0.0208],\n",
      "         [0.0151, 0.0139, 0.0142]]], dtype=torch.float64)\n",
      "torch.Size([128, 64, 3, 3])\n",
      "tensor([[[[0.0673, 0.0301, 0.0149],\n",
      "          [0.0235, 0.0047, 0.0037],\n",
      "          [0.0017, 0.0033, 0.0018]],\n",
      "\n",
      "         [[0.0187, 0.0272, 0.0932],\n",
      "          [0.0493, 0.0093, 0.0628],\n",
      "          [0.0176, 0.0072, 0.0758]],\n",
      "\n",
      "         [[0.0338, 0.0026, 0.0380],\n",
      "          [0.0394, 0.0243, 0.0029],\n",
      "          [0.0045, 0.0334, 0.0282]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0399, 0.0556, 0.0750],\n",
      "          [0.0052, 0.0178, 0.0209],\n",
      "          [0.0464, 0.0217, 0.0013]],\n",
      "\n",
      "         [[0.0075, 0.0386, 0.1558],\n",
      "          [0.0092, 0.0588, 0.0792],\n",
      "          [0.0187, 0.1124, 0.0068]],\n",
      "\n",
      "         [[0.0092, 0.0165, 0.0285],\n",
      "          [0.0185, 0.0245, 0.0032],\n",
      "          [0.0977, 0.0377, 0.0292]]],\n",
      "\n",
      "\n",
      "        [[[0.0018, 0.0214, 0.0167],\n",
      "          [0.0126, 0.0029, 0.0052],\n",
      "          [0.0040, 0.0066, 0.0273]],\n",
      "\n",
      "         [[0.0318, 0.0603, 0.0274],\n",
      "          [0.0006, 0.0111, 0.0189],\n",
      "          [0.0112, 0.0510, 0.0129]],\n",
      "\n",
      "         [[0.0096, 0.0165, 0.0329],\n",
      "          [0.0164, 0.0521, 0.0444],\n",
      "          [0.0204, 0.0093, 0.0089]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0092, 0.0380, 0.0145],\n",
      "          [0.0272, 0.0490, 0.0159],\n",
      "          [0.0128, 0.0724, 0.0594]],\n",
      "\n",
      "         [[0.0232, 0.0063, 0.0202],\n",
      "          [0.0014, 0.0285, 0.0573],\n",
      "          [0.0684, 0.0134, 0.0050]],\n",
      "\n",
      "         [[0.0145, 0.0272, 0.0090],\n",
      "          [0.0355, 0.1035, 0.0345],\n",
      "          [0.0218, 0.0029, 0.0071]]],\n",
      "\n",
      "\n",
      "        [[[0.0034, 0.0130, 0.0006],\n",
      "          [0.0005, 0.0079, 0.0051],\n",
      "          [0.0221, 0.0105, 0.0025]],\n",
      "\n",
      "         [[0.0098, 0.0271, 0.0344],\n",
      "          [0.0649, 0.0506, 0.0633],\n",
      "          [0.0378, 0.0790, 0.0014]],\n",
      "\n",
      "         [[0.0367, 0.0312, 0.0230],\n",
      "          [0.0543, 0.0263, 0.0334],\n",
      "          [0.0007, 0.0018, 0.0218]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0249, 0.0006, 0.0051],\n",
      "          [0.0223, 0.0114, 0.0355],\n",
      "          [0.0284, 0.0027, 0.0283]],\n",
      "\n",
      "         [[0.0132, 0.0218, 0.0335],\n",
      "          [0.0252, 0.0059, 0.0015],\n",
      "          [0.0192, 0.0282, 0.0241]],\n",
      "\n",
      "         [[0.0927, 0.0239, 0.0238],\n",
      "          [0.0641, 0.0020, 0.0434],\n",
      "          [0.0303, 0.0540, 0.0175]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0206, 0.0040, 0.0040],\n",
      "          [0.0186, 0.0345, 0.0144],\n",
      "          [0.0075, 0.0128, 0.0100]],\n",
      "\n",
      "         [[0.0278, 0.0085, 0.0039],\n",
      "          [0.0387, 0.0209, 0.0432],\n",
      "          [0.0395, 0.0560, 0.0257]],\n",
      "\n",
      "         [[0.0041, 0.0159, 0.0247],\n",
      "          [0.0178, 0.0355, 0.0086],\n",
      "          [0.0076, 0.0486, 0.0663]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0196, 0.0514, 0.0372],\n",
      "          [0.0106, 0.0059, 0.0404],\n",
      "          [0.0159, 0.0188, 0.0133]],\n",
      "\n",
      "         [[0.1017, 0.1143, 0.0243],\n",
      "          [0.0373, 0.0399, 0.1145],\n",
      "          [0.0126, 0.0958, 0.0520]],\n",
      "\n",
      "         [[0.0527, 0.1145, 0.0680],\n",
      "          [0.0907, 0.0316, 0.0205],\n",
      "          [0.0882, 0.0482, 0.0003]]],\n",
      "\n",
      "\n",
      "        [[[0.0158, 0.0251, 0.0081],\n",
      "          [0.0058, 0.0116, 0.0213],\n",
      "          [0.0093, 0.0113, 0.0104]],\n",
      "\n",
      "         [[0.0393, 0.1022, 0.1031],\n",
      "          [0.0146, 0.0422, 0.0817],\n",
      "          [0.0351, 0.0320, 0.0554]],\n",
      "\n",
      "         [[0.0316, 0.0356, 0.0652],\n",
      "          [0.0351, 0.0503, 0.0460],\n",
      "          [0.0105, 0.0401, 0.0151]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0452, 0.0201, 0.0096],\n",
      "          [0.0434, 0.0521, 0.0139],\n",
      "          [0.0176, 0.0398, 0.0121]],\n",
      "\n",
      "         [[0.1064, 0.0151, 0.0761],\n",
      "          [0.0298, 0.0182, 0.0542],\n",
      "          [0.0247, 0.0336, 0.0246]],\n",
      "\n",
      "         [[0.0213, 0.0223, 0.0349],\n",
      "          [0.0275, 0.0167, 0.0097],\n",
      "          [0.0145, 0.0281, 0.0525]]],\n",
      "\n",
      "\n",
      "        [[[0.0146, 0.0192, 0.0064],\n",
      "          [0.0079, 0.0132, 0.0093],\n",
      "          [0.0004, 0.0009, 0.0138]],\n",
      "\n",
      "         [[0.0332, 0.0574, 0.0332],\n",
      "          [0.0451, 0.0563, 0.0322],\n",
      "          [0.0051, 0.0015, 0.0211]],\n",
      "\n",
      "         [[0.0395, 0.0010, 0.0345],\n",
      "          [0.0348, 0.0067, 0.0110],\n",
      "          [0.0216, 0.0023, 0.0027]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0148, 0.0426, 0.0096],\n",
      "          [0.0309, 0.0366, 0.0322],\n",
      "          [0.0194, 0.0345, 0.0412]],\n",
      "\n",
      "         [[0.0285, 0.0113, 0.0628],\n",
      "          [0.0923, 0.0322, 0.0704],\n",
      "          [0.0274, 0.0479, 0.0675]],\n",
      "\n",
      "         [[0.0676, 0.0532, 0.0470],\n",
      "          [0.0310, 0.0292, 0.0692],\n",
      "          [0.0009, 0.0237, 0.0530]]]])\n",
      "torch.Size([64, 3, 3])\n",
      "tensor([[[0.0117, 0.0097, 0.0097],\n",
      "         [0.0119, 0.0103, 0.0104],\n",
      "         [0.0117, 0.0097, 0.0110]],\n",
      "\n",
      "        [[0.0197, 0.0220, 0.0202],\n",
      "         [0.0197, 0.0217, 0.0206],\n",
      "         [0.0268, 0.0253, 0.0163]],\n",
      "\n",
      "        [[0.0156, 0.0177, 0.0183],\n",
      "         [0.0179, 0.0170, 0.0182],\n",
      "         [0.0188, 0.0160, 0.0156]],\n",
      "\n",
      "        [[0.0251, 0.0268, 0.0271],\n",
      "         [0.0260, 0.0236, 0.0268],\n",
      "         [0.0237, 0.0218, 0.0217]],\n",
      "\n",
      "        [[0.0078, 0.0085, 0.0085],\n",
      "         [0.0098, 0.0101, 0.0098],\n",
      "         [0.0080, 0.0082, 0.0067]],\n",
      "\n",
      "        [[0.0071, 0.0084, 0.0081],\n",
      "         [0.0091, 0.0116, 0.0080],\n",
      "         [0.0095, 0.0084, 0.0067]],\n",
      "\n",
      "        [[0.0237, 0.0217, 0.0203],\n",
      "         [0.0254, 0.0228, 0.0185],\n",
      "         [0.0207, 0.0224, 0.0238]],\n",
      "\n",
      "        [[0.0221, 0.0198, 0.0178],\n",
      "         [0.0219, 0.0233, 0.0199],\n",
      "         [0.0204, 0.0205, 0.0209]],\n",
      "\n",
      "        [[0.0238, 0.0230, 0.0275],\n",
      "         [0.0271, 0.0280, 0.0266],\n",
      "         [0.0222, 0.0243, 0.0321]],\n",
      "\n",
      "        [[0.0203, 0.0150, 0.0214],\n",
      "         [0.0212, 0.0189, 0.0224],\n",
      "         [0.0224, 0.0172, 0.0204]],\n",
      "\n",
      "        [[0.0161, 0.0166, 0.0153],\n",
      "         [0.0187, 0.0223, 0.0151],\n",
      "         [0.0158, 0.0208, 0.0152]],\n",
      "\n",
      "        [[0.0132, 0.0142, 0.0144],\n",
      "         [0.0134, 0.0129, 0.0150],\n",
      "         [0.0120, 0.0114, 0.0098]],\n",
      "\n",
      "        [[0.0269, 0.0259, 0.0245],\n",
      "         [0.0242, 0.0254, 0.0204],\n",
      "         [0.0290, 0.0308, 0.0266]],\n",
      "\n",
      "        [[0.0191, 0.0178, 0.0161],\n",
      "         [0.0198, 0.0194, 0.0168],\n",
      "         [0.0179, 0.0192, 0.0168]],\n",
      "\n",
      "        [[0.0149, 0.0155, 0.0146],\n",
      "         [0.0173, 0.0152, 0.0157],\n",
      "         [0.0145, 0.0169, 0.0167]],\n",
      "\n",
      "        [[0.0209, 0.0193, 0.0202],\n",
      "         [0.0220, 0.0221, 0.0193],\n",
      "         [0.0189, 0.0230, 0.0260]],\n",
      "\n",
      "        [[0.0102, 0.0143, 0.0118],\n",
      "         [0.0123, 0.0150, 0.0095],\n",
      "         [0.0116, 0.0140, 0.0109]],\n",
      "\n",
      "        [[0.0212, 0.0281, 0.0264],\n",
      "         [0.0223, 0.0217, 0.0359],\n",
      "         [0.0331, 0.0278, 0.0245]],\n",
      "\n",
      "        [[0.0279, 0.0233, 0.0197],\n",
      "         [0.0234, 0.0222, 0.0236],\n",
      "         [0.0232, 0.0218, 0.0219]],\n",
      "\n",
      "        [[0.0230, 0.0253, 0.0204],\n",
      "         [0.0247, 0.0252, 0.0230],\n",
      "         [0.0290, 0.0249, 0.0232]],\n",
      "\n",
      "        [[0.0182, 0.0189, 0.0206],\n",
      "         [0.0201, 0.0227, 0.0218],\n",
      "         [0.0177, 0.0156, 0.0188]],\n",
      "\n",
      "        [[0.0229, 0.0272, 0.0232],\n",
      "         [0.0169, 0.0239, 0.0204],\n",
      "         [0.0214, 0.0213, 0.0229]],\n",
      "\n",
      "        [[0.0209, 0.0267, 0.0222],\n",
      "         [0.0218, 0.0224, 0.0195],\n",
      "         [0.0251, 0.0223, 0.0237]],\n",
      "\n",
      "        [[0.0174, 0.0195, 0.0178],\n",
      "         [0.0234, 0.0188, 0.0194],\n",
      "         [0.0255, 0.0193, 0.0191]],\n",
      "\n",
      "        [[0.0189, 0.0155, 0.0176],\n",
      "         [0.0203, 0.0189, 0.0192],\n",
      "         [0.0201, 0.0188, 0.0211]],\n",
      "\n",
      "        [[0.0163, 0.0174, 0.0162],\n",
      "         [0.0186, 0.0181, 0.0173],\n",
      "         [0.0160, 0.0177, 0.0188]],\n",
      "\n",
      "        [[0.0272, 0.0203, 0.0213],\n",
      "         [0.0248, 0.0252, 0.0251],\n",
      "         [0.0236, 0.0231, 0.0235]],\n",
      "\n",
      "        [[0.0261, 0.0310, 0.0300],\n",
      "         [0.0271, 0.0259, 0.0242],\n",
      "         [0.0250, 0.0296, 0.0302]],\n",
      "\n",
      "        [[0.0161, 0.0127, 0.0139],\n",
      "         [0.0164, 0.0128, 0.0118],\n",
      "         [0.0145, 0.0134, 0.0137]],\n",
      "\n",
      "        [[0.0195, 0.0179, 0.0210],\n",
      "         [0.0210, 0.0202, 0.0190],\n",
      "         [0.0207, 0.0193, 0.0209]],\n",
      "\n",
      "        [[0.0201, 0.0208, 0.0217],\n",
      "         [0.0219, 0.0263, 0.0157],\n",
      "         [0.0193, 0.0215, 0.0169]],\n",
      "\n",
      "        [[0.0195, 0.0198, 0.0209],\n",
      "         [0.0201, 0.0202, 0.0204],\n",
      "         [0.0214, 0.0183, 0.0223]],\n",
      "\n",
      "        [[0.0322, 0.0237, 0.0263],\n",
      "         [0.0263, 0.0338, 0.0250],\n",
      "         [0.0241, 0.0277, 0.0314]],\n",
      "\n",
      "        [[0.0197, 0.0184, 0.0244],\n",
      "         [0.0247, 0.0281, 0.0213],\n",
      "         [0.0193, 0.0203, 0.0190]],\n",
      "\n",
      "        [[0.0103, 0.0142, 0.0124],\n",
      "         [0.0106, 0.0157, 0.0133],\n",
      "         [0.0130, 0.0131, 0.0131]],\n",
      "\n",
      "        [[0.0244, 0.0242, 0.0253],\n",
      "         [0.0266, 0.0236, 0.0207],\n",
      "         [0.0219, 0.0252, 0.0240]],\n",
      "\n",
      "        [[0.0166, 0.0197, 0.0179],\n",
      "         [0.0160, 0.0201, 0.0156],\n",
      "         [0.0187, 0.0177, 0.0183]],\n",
      "\n",
      "        [[0.0132, 0.0153, 0.0120],\n",
      "         [0.0148, 0.0182, 0.0127],\n",
      "         [0.0142, 0.0139, 0.0138]],\n",
      "\n",
      "        [[0.0260, 0.0274, 0.0288],\n",
      "         [0.0249, 0.0285, 0.0222],\n",
      "         [0.0223, 0.0215, 0.0195]],\n",
      "\n",
      "        [[0.0182, 0.0172, 0.0173],\n",
      "         [0.0176, 0.0181, 0.0144],\n",
      "         [0.0134, 0.0179, 0.0140]],\n",
      "\n",
      "        [[0.0214, 0.0214, 0.0275],\n",
      "         [0.0238, 0.0267, 0.0272],\n",
      "         [0.0202, 0.0238, 0.0269]],\n",
      "\n",
      "        [[0.0226, 0.0231, 0.0236],\n",
      "         [0.0255, 0.0270, 0.0229],\n",
      "         [0.0216, 0.0246, 0.0250]],\n",
      "\n",
      "        [[0.0276, 0.0255, 0.0285],\n",
      "         [0.0243, 0.0241, 0.0310],\n",
      "         [0.0225, 0.0211, 0.0234]],\n",
      "\n",
      "        [[0.0094, 0.0094, 0.0079],\n",
      "         [0.0116, 0.0096, 0.0112],\n",
      "         [0.0089, 0.0094, 0.0087]],\n",
      "\n",
      "        [[0.0123, 0.0094, 0.0109],\n",
      "         [0.0105, 0.0142, 0.0119],\n",
      "         [0.0124, 0.0114, 0.0090]],\n",
      "\n",
      "        [[0.0258, 0.0265, 0.0267],\n",
      "         [0.0266, 0.0297, 0.0268],\n",
      "         [0.0249, 0.0277, 0.0273]],\n",
      "\n",
      "        [[0.0282, 0.0231, 0.0239],\n",
      "         [0.0250, 0.0288, 0.0231],\n",
      "         [0.0274, 0.0204, 0.0230]],\n",
      "\n",
      "        [[0.0204, 0.0205, 0.0177],\n",
      "         [0.0166, 0.0188, 0.0213],\n",
      "         [0.0164, 0.0169, 0.0180]],\n",
      "\n",
      "        [[0.0110, 0.0134, 0.0108],\n",
      "         [0.0140, 0.0155, 0.0115],\n",
      "         [0.0120, 0.0101, 0.0121]],\n",
      "\n",
      "        [[0.0104, 0.0118, 0.0080],\n",
      "         [0.0127, 0.0122, 0.0120],\n",
      "         [0.0108, 0.0108, 0.0102]],\n",
      "\n",
      "        [[0.0089, 0.0106, 0.0093],\n",
      "         [0.0093, 0.0138, 0.0101],\n",
      "         [0.0114, 0.0094, 0.0091]],\n",
      "\n",
      "        [[0.0178, 0.0185, 0.0183],\n",
      "         [0.0162, 0.0206, 0.0219],\n",
      "         [0.0175, 0.0168, 0.0194]],\n",
      "\n",
      "        [[0.0176, 0.0217, 0.0201],\n",
      "         [0.0167, 0.0178, 0.0197],\n",
      "         [0.0162, 0.0192, 0.0199]],\n",
      "\n",
      "        [[0.0137, 0.0137, 0.0107],\n",
      "         [0.0141, 0.0139, 0.0161],\n",
      "         [0.0143, 0.0146, 0.0170]],\n",
      "\n",
      "        [[0.0143, 0.0137, 0.0142],\n",
      "         [0.0143, 0.0159, 0.0171],\n",
      "         [0.0150, 0.0161, 0.0167]],\n",
      "\n",
      "        [[0.0263, 0.0232, 0.0283],\n",
      "         [0.0241, 0.0277, 0.0236],\n",
      "         [0.0271, 0.0232, 0.0203]],\n",
      "\n",
      "        [[0.0252, 0.0243, 0.0163],\n",
      "         [0.0253, 0.0234, 0.0169],\n",
      "         [0.0214, 0.0224, 0.0171]],\n",
      "\n",
      "        [[0.0234, 0.0219, 0.0276],\n",
      "         [0.0224, 0.0309, 0.0249],\n",
      "         [0.0240, 0.0239, 0.0252]],\n",
      "\n",
      "        [[0.0199, 0.0205, 0.0223],\n",
      "         [0.0211, 0.0232, 0.0185],\n",
      "         [0.0189, 0.0180, 0.0187]],\n",
      "\n",
      "        [[0.0136, 0.0147, 0.0171],\n",
      "         [0.0124, 0.0161, 0.0149],\n",
      "         [0.0153, 0.0142, 0.0130]],\n",
      "\n",
      "        [[0.0296, 0.0248, 0.0288],\n",
      "         [0.0289, 0.0226, 0.0249],\n",
      "         [0.0240, 0.0239, 0.0274]],\n",
      "\n",
      "        [[0.0174, 0.0204, 0.0211],\n",
      "         [0.0178, 0.0182, 0.0200],\n",
      "         [0.0178, 0.0170, 0.0166]],\n",
      "\n",
      "        [[0.0331, 0.0314, 0.0335],\n",
      "         [0.0294, 0.0261, 0.0355],\n",
      "         [0.0262, 0.0310, 0.0384]],\n",
      "\n",
      "        [[0.0206, 0.0278, 0.0262],\n",
      "         [0.0258, 0.0256, 0.0263],\n",
      "         [0.0255, 0.0231, 0.0267]]], dtype=torch.float64)\n",
      "torch.Size([256, 128, 3, 3])\n",
      "tensor([[[[0.0299, 0.0263, 0.0277],\n",
      "          [0.0138, 0.0163, 0.0420],\n",
      "          [0.0249, 0.0088, 0.0068]],\n",
      "\n",
      "         [[0.0060, 0.0017, 0.0021],\n",
      "          [0.0033, 0.0165, 0.0011],\n",
      "          [0.0078, 0.0047, 0.0016]],\n",
      "\n",
      "         [[0.0420, 0.0142, 0.0215],\n",
      "          [0.0306, 0.0023, 0.0131],\n",
      "          [0.0144, 0.0245, 0.0344]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0143, 0.0035, 0.0114],\n",
      "          [0.0127, 0.0500, 0.0023],\n",
      "          [0.0064, 0.0075, 0.0089]],\n",
      "\n",
      "         [[0.0113, 0.0263, 0.0402],\n",
      "          [0.0124, 0.0100, 0.0121],\n",
      "          [0.0279, 0.0216, 0.0192]],\n",
      "\n",
      "         [[0.0306, 0.0211, 0.0064],\n",
      "          [0.0218, 0.0096, 0.0016],\n",
      "          [0.0241, 0.0240, 0.0008]]],\n",
      "\n",
      "\n",
      "        [[[0.0495, 0.0249, 0.0191],\n",
      "          [0.0320, 0.0146, 0.0109],\n",
      "          [0.0175, 0.0044, 0.0436]],\n",
      "\n",
      "         [[0.0063, 0.0036, 0.0292],\n",
      "          [0.0388, 0.0488, 0.0169],\n",
      "          [0.0156, 0.0095, 0.0090]],\n",
      "\n",
      "         [[0.0157, 0.0136, 0.0284],\n",
      "          [0.0360, 0.0491, 0.0269],\n",
      "          [0.0134, 0.0453, 0.0099]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0191, 0.0054, 0.0009],\n",
      "          [0.0307, 0.0374, 0.0060],\n",
      "          [0.0041, 0.0284, 0.0378]],\n",
      "\n",
      "         [[0.0674, 0.0307, 0.0234],\n",
      "          [0.0044, 0.0224, 0.0361],\n",
      "          [0.0329, 0.0534, 0.0017]],\n",
      "\n",
      "         [[0.0341, 0.0218, 0.0069],\n",
      "          [0.0014, 0.0326, 0.0058],\n",
      "          [0.0270, 0.0078, 0.0058]]],\n",
      "\n",
      "\n",
      "        [[[0.0245, 0.0136, 0.0035],\n",
      "          [0.0345, 0.0323, 0.0164],\n",
      "          [0.0464, 0.0426, 0.0018]],\n",
      "\n",
      "         [[0.0150, 0.0035, 0.0008],\n",
      "          [0.0162, 0.0139, 0.0556],\n",
      "          [0.0418, 0.0343, 0.0711]],\n",
      "\n",
      "         [[0.0405, 0.0130, 0.0528],\n",
      "          [0.0048, 0.0268, 0.0770],\n",
      "          [0.0278, 0.0396, 0.0051]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0148, 0.0221, 0.0562],\n",
      "          [0.0228, 0.0009, 0.0163],\n",
      "          [0.0340, 0.0154, 0.0326]],\n",
      "\n",
      "         [[0.0401, 0.0053, 0.0070],\n",
      "          [0.0155, 0.0214, 0.0133],\n",
      "          [0.0035, 0.0252, 0.0406]],\n",
      "\n",
      "         [[0.0271, 0.0155, 0.0030],\n",
      "          [0.0003, 0.0230, 0.0548],\n",
      "          [0.0116, 0.0327, 0.0098]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0060, 0.0004, 0.0081],\n",
      "          [0.0099, 0.0077, 0.0047],\n",
      "          [0.0063, 0.0107, 0.0165]],\n",
      "\n",
      "         [[0.0078, 0.0251, 0.0245],\n",
      "          [0.0071, 0.0067, 0.0110],\n",
      "          [0.0040, 0.0083, 0.0082]],\n",
      "\n",
      "         [[0.0050, 0.0128, 0.0068],\n",
      "          [0.0041, 0.0010, 0.0025],\n",
      "          [0.0061, 0.0129, 0.0118]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0426, 0.0093, 0.0014],\n",
      "          [0.0194, 0.0024, 0.0053],\n",
      "          [0.0064, 0.0021, 0.0088]],\n",
      "\n",
      "         [[0.0047, 0.0221, 0.0267],\n",
      "          [0.0353, 0.0270, 0.0041],\n",
      "          [0.0331, 0.0234, 0.0330]],\n",
      "\n",
      "         [[0.0106, 0.0089, 0.0052],\n",
      "          [0.0126, 0.0141, 0.0145],\n",
      "          [0.0283, 0.0247, 0.0062]]],\n",
      "\n",
      "\n",
      "        [[[0.0306, 0.0095, 0.0142],\n",
      "          [0.0217, 0.0640, 0.0356],\n",
      "          [0.0305, 0.0273, 0.0357]],\n",
      "\n",
      "         [[0.0144, 0.0063, 0.0109],\n",
      "          [0.0055, 0.0393, 0.0189],\n",
      "          [0.0226, 0.0127, 0.0075]],\n",
      "\n",
      "         [[0.0008, 0.0275, 0.0181],\n",
      "          [0.0315, 0.0073, 0.0179],\n",
      "          [0.0014, 0.0062, 0.0364]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0049, 0.0008, 0.0027],\n",
      "          [0.0132, 0.0144, 0.0549],\n",
      "          [0.0200, 0.0051, 0.0056]],\n",
      "\n",
      "         [[0.0075, 0.0266, 0.0203],\n",
      "          [0.0141, 0.0524, 0.0041],\n",
      "          [0.0013, 0.0081, 0.0654]],\n",
      "\n",
      "         [[0.0032, 0.0065, 0.0125],\n",
      "          [0.0020, 0.0269, 0.0280],\n",
      "          [0.0038, 0.0166, 0.0109]]],\n",
      "\n",
      "\n",
      "        [[[0.0242, 0.0148, 0.0064],\n",
      "          [0.0053, 0.0185, 0.0586],\n",
      "          [0.0093, 0.0225, 0.0177]],\n",
      "\n",
      "         [[0.0300, 0.0344, 0.0005],\n",
      "          [0.0103, 0.0130, 0.0160],\n",
      "          [0.0129, 0.0020, 0.0035]],\n",
      "\n",
      "         [[0.0072, 0.0376, 0.0619],\n",
      "          [0.0235, 0.0050, 0.0092],\n",
      "          [0.0179, 0.0021, 0.0074]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0191, 0.0241, 0.0092],\n",
      "          [0.0213, 0.0133, 0.0109],\n",
      "          [0.0189, 0.0370, 0.0242]],\n",
      "\n",
      "         [[0.0223, 0.0148, 0.0016],\n",
      "          [0.0143, 0.0031, 0.0235],\n",
      "          [0.0269, 0.0089, 0.0116]],\n",
      "\n",
      "         [[0.0220, 0.0239, 0.0037],\n",
      "          [0.0272, 0.0258, 0.0161],\n",
      "          [0.0083, 0.0005, 0.0182]]]])\n",
      "torch.Size([128, 3, 3])\n",
      "tensor([[[0.0172, 0.0137, 0.0158],\n",
      "         [0.0154, 0.0140, 0.0167],\n",
      "         [0.0159, 0.0143, 0.0150]],\n",
      "\n",
      "        [[0.0122, 0.0140, 0.0130],\n",
      "         [0.0113, 0.0145, 0.0121],\n",
      "         [0.0121, 0.0113, 0.0116]],\n",
      "\n",
      "        [[0.0176, 0.0164, 0.0196],\n",
      "         [0.0181, 0.0195, 0.0171],\n",
      "         [0.0187, 0.0148, 0.0134]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0166, 0.0161, 0.0144],\n",
      "         [0.0150, 0.0159, 0.0173],\n",
      "         [0.0150, 0.0153, 0.0177]],\n",
      "\n",
      "        [[0.0168, 0.0189, 0.0207],\n",
      "         [0.0166, 0.0168, 0.0188],\n",
      "         [0.0191, 0.0189, 0.0174]],\n",
      "\n",
      "        [[0.0139, 0.0149, 0.0129],\n",
      "         [0.0129, 0.0129, 0.0133],\n",
      "         [0.0124, 0.0116, 0.0127]]], dtype=torch.float64)\n",
      "torch.Size([256, 256, 3, 3])\n",
      "tensor([[[[1.4614e-02, 5.7132e-03, 3.8659e-03],\n",
      "          [1.0361e-02, 9.2700e-05, 5.1997e-04],\n",
      "          [6.3489e-04, 1.8407e-03, 7.3896e-03]],\n",
      "\n",
      "         [[3.9751e-03, 7.3803e-03, 6.9929e-03],\n",
      "          [7.5335e-03, 1.8496e-03, 6.9713e-03],\n",
      "          [1.0579e-02, 5.0674e-03, 7.1991e-03]],\n",
      "\n",
      "         [[1.3403e-03, 4.1911e-03, 5.1716e-03],\n",
      "          [6.9333e-03, 6.0812e-03, 1.0989e-02],\n",
      "          [1.4856e-03, 1.2456e-02, 1.7562e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[6.7693e-03, 9.6115e-04, 3.2484e-03],\n",
      "          [2.5032e-03, 6.5840e-03, 9.6467e-03],\n",
      "          [8.2448e-03, 3.6977e-03, 6.9298e-03]],\n",
      "\n",
      "         [[7.2749e-03, 1.0362e-02, 5.4380e-03],\n",
      "          [3.7567e-03, 1.2470e-03, 5.9641e-03],\n",
      "          [4.0792e-03, 9.1702e-03, 1.8037e-03]],\n",
      "\n",
      "         [[7.5355e-06, 1.8515e-04, 7.7071e-03],\n",
      "          [6.9359e-03, 6.2129e-03, 1.3542e-02],\n",
      "          [1.7391e-02, 1.1922e-02, 1.6190e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.2172e-04, 8.0698e-05, 4.4905e-04],\n",
      "          [3.2571e-04, 1.6634e-05, 6.7864e-04],\n",
      "          [1.7746e-04, 1.4760e-03, 9.3688e-04]],\n",
      "\n",
      "         [[2.5890e-04, 3.6163e-04, 4.7962e-05],\n",
      "          [9.1058e-04, 5.5494e-05, 3.8474e-05],\n",
      "          [1.4113e-03, 1.1408e-03, 2.0011e-04]],\n",
      "\n",
      "         [[3.5851e-04, 6.8381e-04, 1.0143e-03],\n",
      "          [1.0607e-03, 3.8691e-04, 8.2586e-04],\n",
      "          [1.4821e-04, 9.3249e-04, 7.4078e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[4.7316e-04, 5.0315e-05, 6.5782e-04],\n",
      "          [3.3364e-04, 8.4031e-05, 5.5268e-04],\n",
      "          [6.7498e-04, 5.0747e-05, 1.1436e-04]],\n",
      "\n",
      "         [[1.8777e-04, 1.3833e-04, 4.1714e-04],\n",
      "          [1.0911e-03, 5.6659e-04, 9.4606e-04],\n",
      "          [3.6168e-04, 2.6436e-04, 1.7634e-04]],\n",
      "\n",
      "         [[4.9686e-04, 8.7088e-04, 6.4682e-04],\n",
      "          [1.1948e-03, 1.3208e-03, 2.9413e-04],\n",
      "          [1.4379e-03, 1.5162e-03, 1.2000e-03]]],\n",
      "\n",
      "\n",
      "        [[[2.0594e-02, 3.0932e-02, 3.0111e-02],\n",
      "          [1.5251e-02, 2.7646e-02, 6.9626e-03],\n",
      "          [2.3339e-02, 5.7227e-02, 2.7821e-02]],\n",
      "\n",
      "         [[2.1518e-02, 1.0231e-01, 4.6167e-02],\n",
      "          [8.8545e-02, 5.8707e-02, 6.7163e-03],\n",
      "          [9.9426e-02, 1.8592e-02, 1.4425e-02]],\n",
      "\n",
      "         [[1.1853e-02, 8.0627e-03, 7.2801e-02],\n",
      "          [2.6522e-02, 6.7628e-02, 1.2031e-03],\n",
      "          [2.3424e-02, 2.6280e-03, 4.5699e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[3.8410e-02, 1.5229e-02, 8.1858e-03],\n",
      "          [2.7779e-02, 1.8977e-02, 4.5196e-03],\n",
      "          [2.5335e-03, 8.2605e-03, 8.0610e-03]],\n",
      "\n",
      "         [[6.4755e-02, 7.3715e-02, 8.5022e-02],\n",
      "          [5.2367e-02, 1.7082e-02, 2.0063e-03],\n",
      "          [8.2492e-02, 7.1347e-02, 3.5835e-03]],\n",
      "\n",
      "         [[1.2882e-02, 1.2864e-02, 1.9018e-03],\n",
      "          [4.4978e-03, 7.1434e-03, 3.4514e-02],\n",
      "          [1.9628e-02, 3.6538e-02, 3.1441e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[2.1993e-02, 1.1881e-03, 2.1024e-02],\n",
      "          [2.3881e-03, 5.1209e-02, 4.4676e-02],\n",
      "          [2.1716e-03, 4.8187e-02, 2.5284e-02]],\n",
      "\n",
      "         [[2.3511e-02, 6.2558e-02, 9.2238e-02],\n",
      "          [5.9274e-02, 3.5920e-02, 4.6262e-02],\n",
      "          [1.2716e-01, 4.8112e-03, 5.9382e-02]],\n",
      "\n",
      "         [[4.6112e-02, 1.0048e-02, 5.3618e-03],\n",
      "          [4.6602e-03, 4.3716e-02, 7.5874e-02],\n",
      "          [3.4242e-03, 2.4443e-02, 5.6348e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.2971e-02, 2.3310e-02, 6.3394e-03],\n",
      "          [2.3645e-02, 3.4604e-02, 2.0707e-03],\n",
      "          [1.3797e-02, 4.2261e-02, 3.8004e-03]],\n",
      "\n",
      "         [[2.7680e-02, 2.1763e-02, 9.4548e-02],\n",
      "          [6.2129e-02, 1.6491e-02, 4.0866e-02],\n",
      "          [4.7028e-02, 2.8506e-02, 3.9403e-02]],\n",
      "\n",
      "         [[8.5703e-03, 1.8941e-02, 4.2166e-02],\n",
      "          [2.6993e-02, 8.8459e-03, 8.4669e-02],\n",
      "          [3.6253e-02, 4.9295e-02, 2.5215e-03]]],\n",
      "\n",
      "\n",
      "        [[[2.0293e-02, 5.5603e-03, 2.6376e-02],\n",
      "          [6.4130e-02, 4.2605e-02, 1.2420e-02],\n",
      "          [1.9173e-02, 1.4281e-02, 4.4297e-02]],\n",
      "\n",
      "         [[3.2506e-02, 6.5925e-02, 7.5202e-02],\n",
      "          [3.6287e-02, 1.2584e-02, 2.9477e-02],\n",
      "          [3.3982e-02, 1.4658e-02, 1.7389e-03]],\n",
      "\n",
      "         [[1.0160e-01, 3.2962e-02, 3.3460e-02],\n",
      "          [2.7021e-02, 5.5413e-02, 2.8602e-02],\n",
      "          [8.2876e-03, 2.9841e-02, 5.3041e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.0014e-02, 9.4142e-04, 4.1097e-02],\n",
      "          [1.1288e-02, 2.9555e-02, 2.8820e-02],\n",
      "          [3.2102e-02, 2.6842e-02, 4.9386e-03]],\n",
      "\n",
      "         [[4.7924e-02, 7.2713e-02, 2.6175e-02],\n",
      "          [8.1814e-02, 3.9128e-02, 1.2369e-02],\n",
      "          [7.5202e-03, 1.3892e-02, 2.3351e-02]],\n",
      "\n",
      "         [[9.9045e-05, 1.2862e-02, 5.4389e-02],\n",
      "          [1.9227e-02, 4.5581e-02, 9.5463e-03],\n",
      "          [3.3847e-02, 4.0022e-02, 5.3000e-02]]],\n",
      "\n",
      "\n",
      "        [[[4.7641e-02, 1.6305e-02, 3.7111e-02],\n",
      "          [1.1608e-02, 3.0024e-02, 4.4352e-02],\n",
      "          [3.1813e-02, 3.9948e-02, 7.0497e-02]],\n",
      "\n",
      "         [[1.2104e-02, 3.0344e-02, 4.3919e-02],\n",
      "          [7.9774e-02, 4.5085e-02, 7.5825e-03],\n",
      "          [4.1837e-02, 4.0477e-02, 2.9330e-02]],\n",
      "\n",
      "         [[3.9169e-02, 9.2713e-02, 2.7593e-02],\n",
      "          [2.8792e-02, 1.1066e-01, 3.1200e-02],\n",
      "          [5.3422e-02, 4.5812e-02, 5.2284e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.9116e-02, 1.5688e-02, 1.1108e-02],\n",
      "          [1.5668e-02, 1.4449e-02, 8.3889e-03],\n",
      "          [1.6841e-02, 4.6065e-03, 1.9819e-02]],\n",
      "\n",
      "         [[2.5534e-02, 8.5727e-02, 4.7040e-02],\n",
      "          [1.1302e-01, 6.8105e-02, 3.7661e-02],\n",
      "          [3.6153e-03, 1.0468e-01, 2.2214e-02]],\n",
      "\n",
      "         [[1.8223e-02, 6.7424e-03, 5.6598e-03],\n",
      "          [4.1517e-03, 2.7984e-02, 9.5884e-03],\n",
      "          [3.5890e-02, 2.3825e-02, 1.4588e-02]]]])\n",
      "torch.Size([256, 3, 3])\n",
      "tensor([[[0.0168, 0.0159, 0.0176],\n",
      "         [0.0170, 0.0174, 0.0206],\n",
      "         [0.0195, 0.0202, 0.0212]],\n",
      "\n",
      "        [[0.0239, 0.0285, 0.0252],\n",
      "         [0.0244, 0.0249, 0.0239],\n",
      "         [0.0287, 0.0236, 0.0232]],\n",
      "\n",
      "        [[0.0308, 0.0318, 0.0259],\n",
      "         [0.0293, 0.0306, 0.0270],\n",
      "         [0.0250, 0.0292, 0.0296]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0123, 0.0118, 0.0112],\n",
      "         [0.0130, 0.0146, 0.0117],\n",
      "         [0.0097, 0.0118, 0.0106]],\n",
      "\n",
      "        [[0.0325, 0.0281, 0.0287],\n",
      "         [0.0307, 0.0297, 0.0339],\n",
      "         [0.0210, 0.0315, 0.0310]],\n",
      "\n",
      "        [[0.0190, 0.0217, 0.0199],\n",
      "         [0.0189, 0.0204, 0.0232],\n",
      "         [0.0171, 0.0194, 0.0182]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Test of L1 pruning\n",
    "state_dict = torch.load('state_dict__cifarnet.pt')\n",
    "for key in state_dict:\n",
    "    print(key)\n",
    "\n",
    "for num in range(6):\n",
    "    # print(f'\\nnum: {num}')\n",
    "    conv_layer = state_dict.get('conv{}.weight'.format(num+1))\n",
    "    #print(conv_layer)\n",
    "    \n",
    "    conv_layer_flattened = conv_layer.abs().cpu().numpy().flatten()\n",
    "    #print(conv_layer_flattened)\n",
    "    threshold = np.percentile(conv_layer_flattened, 50)\n",
    "    print(threshold)\n",
    "\n",
    "    #conv_mask = conv_layer.abs() >= threshold\n",
    "    conv_mask = conv_layer\n",
    "    conv_mask = torch.where(conv_mask.abs()<threshold, 0.0, 1.0)\n",
    "    \n",
    "    # print(\"BEFORE:\\t#####################################\")\n",
    "    # print(state_dict.get('conv{}.weight'.format(num+1)))\n",
    "    state_dict['conv{}.weight'.format(num+1)] = conv_layer*conv_mask\n",
    "    # print(\"AFTER:\\t#####################################\")\n",
    "    # print(state_dict.get('conv{}.weight'.format(num+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "signed-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def random_unstructured_pruning(state_dict: Dict, prune_ratio: float) -> Dict:\n",
    "    state_dict = copy.deepcopy(state_dict)\n",
    "    #set values in conv filters to zero according to the prune ratio\n",
    "    # to-be-done-by-student------\n",
    "    for num in range(6):\n",
    "        conv_layer = state_dict.get('conv{}.weight'.format(num+1))\n",
    "                                    \n",
    "        conv_mask = torch.rand(conv_layer.shape)\n",
    "        conv_mask = torch.where(conv_mask<prune_ratio, 0.0, 1.0)\n",
    "\n",
    "        state_dict['conv{}.weight'.format(num+1)] = conv_layer*conv_mask\n",
    "        \n",
    "    #----------------------------\n",
    "    return state_dict\n",
    "\n",
    "def l1_unstructured_pruning(state_dict: Dict, prune_ratio: float) -> Dict:\n",
    "    state_dict = copy.deepcopy(state_dict)\n",
    "    #set values in conv filters to zero according to the prune ratio\n",
    "    #---to be done by student---\n",
    "    for num in range(6):\n",
    "        conv_layer = state_dict.get('conv{}.weight'.format(num+1))\n",
    "        conv_layer_flattened = conv_layer.abs().cpu().numpy().flatten()\n",
    "\n",
    "        threshold = np.percentile(conv_layer_flattened, prune_ratio*100)\n",
    "    \n",
    "        conv_mask = conv_layer\n",
    "        conv_mask = torch.where(conv_mask.abs()<threshold, 0.0, 1.0)\n",
    "        \n",
    "        state_dict['conv{}.weight'.format(num+1)] = conv_layer*conv_mask\n",
    "    #---end---------------------\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-million",
   "metadata": {},
   "source": [
    "The following code plots the differences between random and l1 pruning. The plot is saved on disk with the filename `size_on_disk.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "stock-elevation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15/15 [01:41<00:00,  6.76s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tqdm\n",
    "from utils import plot\n",
    "ratios = [i/15.0 for i in  range(15)]\n",
    "sd = torch.load('state_dict__cifarnet.pt')\n",
    "accs_random, size_random = [], []\n",
    "for ratio in tqdm.tqdm(ratios):\n",
    "    \n",
    "    # Apply random unstructured pruning \n",
    "    sd_pruned = random_unstructured_pruning(sd, ratio)\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    accs_random.append(net_acc(CifarNet, sd_pruned, testloader, batches=32, device='cuda'))\n",
    "    \n",
    "    # Evaluate size of network on disk (gzip)\n",
    "    size_random.append(size_on_disk(sd_pruned)[0])\n",
    "    \n",
    "accs_l1, size_l1 = [], []\n",
    "for ratio in tqdm.tqdm(ratios):\n",
    "    # Apply L1 unstructued pruning\n",
    "    sd_pruned = l1_unstructured_pruning(sd, ratio)\n",
    "    accs_l1.append(net_acc(CifarNet, sd_pruned, testloader, batches=32, device='cuda'))\n",
    "    size_l1.append(size_on_disk(sd_pruned)[0])\n",
    "\n",
    "    \n",
    "plot([(size_random, accs_random, 'accuracy_random'),\n",
    "      (size_l1, accs_l1, 'accuracy_l1')],\n",
    "      xlabel='size on disk [relative to max]', save_path='size_on_disk.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
